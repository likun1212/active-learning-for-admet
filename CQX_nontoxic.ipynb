{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "torch.manual_seed(8) # for reproduce\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "# from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from IPython.display import SVG, display\n",
    "import seaborn as sns; sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  11006\n",
      "number of successfully processed smiles:  11006\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = 'nontoxic'\n",
    "tasks = ['nontoxic']\n",
    "raw_filename = \"../data/total_nontoxic.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(\"not successfully processed smiles: \", smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)]\n",
    "# print(smiles_tasks_df)\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "assert canonical_smiles_list[8]==Chem.MolToSmiles(Chem.MolFromSmiles(smiles_tasks_df['cano_smiles'][8]), isomericSmiles=True)\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# print(len([i for i in atom_num_dist if i<51]),len([i for i in atom_num_dist if i>50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 188\n",
    "random_seed = int(time.time())\n",
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 800\n",
    "p_dropout = 0.1\n",
    "fingerprint_dim = 150\n",
    "\n",
    "radius = 3\n",
    "T = 2\n",
    "weight_decay = 2.9 # also known as l2_regularization_lambda\n",
    "learning_rate = 3.5\n",
    "per_task_output_units_num = 2 # for classification model with 2 classes\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nontoxic</th>\n",
       "      <th>smiles</th>\n",
       "      <th>cano_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7866</th>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nontoxic smiles cano_smiles\n",
       "7866         1      C           C"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smilesList = [smiles for smiles in canonical_smiles_list if len(Chem.MolFromSmiles(smiles).GetAtoms())<101]\n",
    "uncovered = [smiles for smiles in canonical_smiles_list if len(Chem.MolFromSmiles(smiles).GetAtoms())>100]\n",
    "\n",
    "smiles_tasks_df = smiles_tasks_df[~smiles_tasks_df[\"cano_smiles\"].isin(uncovered)]\n",
    "\n",
    "if os.path.isfile(feature_filename):\n",
    "    feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "else:\n",
    "    feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "# feature_dicts = get_smiles_dicts(smilesList)\n",
    "\n",
    "remained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = smiles_tasks_df.drop(remained_df.index)\n",
    "uncovered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for i,task in enumerate(tasks):    \n",
    "    negative_df = remained_df[remained_df[task] == 0][[\"smiles\",task]]\n",
    "    positive_df = remained_df[remained_df[task] == 1][[\"smiles\",task]]\n",
    "    weights.append([(positive_df.shape[0]+negative_df.shape[0])/negative_df.shape[0],\\\n",
    "                    (positive_df.shape[0]+negative_df.shape[0])/positive_df.shape[0]])\n",
    "    \n",
    "test_df=remained_df.tail(2603)\n",
    "training_data = remained_df.drop(test_df.index) # training data\n",
    "\n",
    "# training data is further divided into validation set and train set\n",
    "valid_df = training_data.sample(frac=1/5, random_state=random_seed) # validation set\n",
    "train_df = training_data.drop(valid_df.index) # train set\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649206\n",
      "atom_fc.weight torch.Size([150, 39])\n",
      "atom_fc.bias torch.Size([150])\n",
      "neighbor_fc.weight torch.Size([150, 49])\n",
      "neighbor_fc.bias torch.Size([150])\n",
      "GRUCell.0.weight_ih torch.Size([450, 150])\n",
      "GRUCell.0.weight_hh torch.Size([450, 150])\n",
      "GRUCell.0.bias_ih torch.Size([450])\n",
      "GRUCell.0.bias_hh torch.Size([450])\n",
      "GRUCell.1.weight_ih torch.Size([450, 150])\n",
      "GRUCell.1.weight_hh torch.Size([450, 150])\n",
      "GRUCell.1.bias_ih torch.Size([450])\n",
      "GRUCell.1.bias_hh torch.Size([450])\n",
      "GRUCell.2.weight_ih torch.Size([450, 150])\n",
      "GRUCell.2.weight_hh torch.Size([450, 150])\n",
      "GRUCell.2.bias_ih torch.Size([450])\n",
      "GRUCell.2.bias_hh torch.Size([450])\n",
      "align.0.weight torch.Size([1, 300])\n",
      "align.0.bias torch.Size([1])\n",
      "align.1.weight torch.Size([1, 300])\n",
      "align.1.bias torch.Size([1])\n",
      "align.2.weight torch.Size([1, 300])\n",
      "align.2.bias torch.Size([1])\n",
      "attend.0.weight torch.Size([150, 150])\n",
      "attend.0.bias torch.Size([150])\n",
      "attend.1.weight torch.Size([150, 150])\n",
      "attend.1.bias torch.Size([150])\n",
      "attend.2.weight torch.Size([150, 150])\n",
      "attend.2.bias torch.Size([150])\n",
      "mol_GRUCell.weight_ih torch.Size([450, 150])\n",
      "mol_GRUCell.weight_hh torch.Size([450, 150])\n",
      "mol_GRUCell.bias_ih torch.Size([450])\n",
      "mol_GRUCell.bias_hh torch.Size([450])\n",
      "mol_align.weight torch.Size([1, 300])\n",
      "mol_align.bias torch.Size([1])\n",
      "mol_attend.weight torch.Size([150, 150])\n",
      "mol_attend.bias torch.Size([150])\n",
      "output.weight torch.Size([2, 150])\n",
      "output.bias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([smilesList[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "\n",
    "loss_function = [nn.CrossEntropyLoss(torch.Tensor(weight),reduction='mean') for weight in weights]\n",
    "model = Fingerprint(radius, T, num_atom_features,num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "model.cuda()\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, optimizer, loss_function):\n",
    "    model.train()\n",
    "    np.random.seed(epoch)\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "#         print(torch.Tensor(x_atom).size(),torch.Tensor(x_bonds).size(),torch.cuda.LongTensor(x_atom_index).size(),torch.cuda.LongTensor(x_bond_index).size(),torch.Tensor(x_mask).size())\n",
    "        \n",
    "        model.zero_grad()\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target wrapped in a variable)\n",
    "        loss = 0.0\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where(y_val != -1)[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "\n",
    "            loss += loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where((y_val=='0') | (y_val=='1'))[0]\n",
    "#             print(validInds)\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "#             print(validInds)\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "#             print(y_pred_adjust)\n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            try:\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                y_val_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)            \n",
    "    test_roc = [roc_auc_score(y_val_list[i], y_pred_list[i]) for i in range(len(tasks))]\n",
    "    test_prc = [auc(precision_recall_curve(y_val_list[i], y_pred_list[i])[1],precision_recall_curve(y_val_list[i], y_pred_list[i])[0]) for i in range(len(tasks))]\n",
    "#     test_prc = auc(recall, precision)\n",
    "    test_precision = [precision_score(y_val_list[i],\n",
    "                                     (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_recall = [recall_score(y_val_list[i],\n",
    "                               (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_loss = np.array(losses_list).mean()\n",
    "    \n",
    "    return test_roc, test_prc, test_precision, test_recall, test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:\t0\n",
      "train_roc:[0.7597760335190684]\n",
      "valid_roc:[0.7634708281507623]\n",
      "\n",
      "EPOCH:\t1\n",
      "train_roc:[0.7645609477695883]\n",
      "valid_roc:[0.7627201990107315]\n",
      "\n",
      "EPOCH:\t2\n",
      "train_roc:[0.7675550319807538]\n",
      "valid_roc:[0.7687599433050823]\n",
      "\n",
      "EPOCH:\t3\n",
      "train_roc:[0.7661192324040795]\n",
      "valid_roc:[0.7663851204767]\n",
      "\n",
      "EPOCH:\t4\n",
      "train_roc:[0.7678192039221242]\n",
      "valid_roc:[0.7638483121691592]\n",
      "\n",
      "EPOCH:\t5\n",
      "train_roc:[0.7705333932851983]\n",
      "valid_roc:[0.7686456856903185]\n",
      "\n",
      "EPOCH:\t6\n",
      "train_roc:[0.7655412348590215]\n",
      "valid_roc:[0.762710074918284]\n",
      "\n",
      "EPOCH:\t7\n",
      "train_roc:[0.7693717505992776]\n",
      "valid_roc:[0.7682407219924214]\n",
      "\n",
      "EPOCH:\t8\n",
      "train_roc:[0.7683073821035007]\n",
      "valid_roc:[0.7731161956553182]\n",
      "\n",
      "EPOCH:\t9\n",
      "train_roc:[0.7678877883255791]\n",
      "valid_roc:[0.7651282867142981]\n",
      "\n",
      "EPOCH:\t10\n",
      "train_roc:[0.7775199662843048]\n",
      "valid_roc:[0.7774247201411588]\n",
      "\n",
      "EPOCH:\t11\n",
      "train_roc:[0.7778473461179239]\n",
      "valid_roc:[0.7784139886031645]\n",
      "\n",
      "EPOCH:\t12\n",
      "train_roc:[0.7797919263054711]\n",
      "valid_roc:[0.7802052298168984]\n",
      "\n",
      "EPOCH:\t13\n",
      "train_roc:[0.7788119554814028]\n",
      "valid_roc:[0.7816001851262617]\n",
      "\n",
      "EPOCH:\t14\n",
      "train_roc:[0.7764869080596704]\n",
      "valid_roc:[0.7761071418240723]\n",
      "\n",
      "EPOCH:\t15\n",
      "train_roc:[0.7821791876425905]\n",
      "valid_roc:[0.7810057562697059]\n",
      "\n",
      "EPOCH:\t16\n",
      "train_roc:[0.7821744888428808]\n",
      "valid_roc:[0.7828194151167164]\n",
      "\n",
      "EPOCH:\t17\n",
      "train_roc:[0.7859070075007302]\n",
      "valid_roc:[0.7843785253536201]\n",
      "\n",
      "EPOCH:\t18\n",
      "train_roc:[0.7870469634187599]\n",
      "valid_roc:[0.7877860056116399]\n",
      "\n",
      "EPOCH:\t19\n",
      "train_roc:[0.7873708191525967]\n",
      "valid_roc:[0.7875502588875068]\n",
      "\n",
      "EPOCH:\t20\n",
      "train_roc:[0.7869655928584027]\n",
      "valid_roc:[0.7879422058951144]\n",
      "\n",
      "EPOCH:\t21\n",
      "train_roc:[0.7900191349582024]\n",
      "valid_roc:[0.7895707384802291]\n",
      "\n",
      "EPOCH:\t22\n",
      "train_roc:[0.7903918762813266]\n",
      "valid_roc:[0.7904775679037344]\n",
      "\n",
      "EPOCH:\t23\n",
      "train_roc:[0.7923784745816622]\n",
      "valid_roc:[0.7911428654074223]\n",
      "\n",
      "EPOCH:\t24\n",
      "train_roc:[0.791957389838448]\n",
      "valid_roc:[0.7927149923346156]\n",
      "\n",
      "EPOCH:\t25\n",
      "train_roc:[0.7936603432870779]\n",
      "valid_roc:[0.7933267767782244]\n",
      "\n",
      "EPOCH:\t26\n",
      "train_roc:[0.793474198529348]\n",
      "valid_roc:[0.7933267767782244]\n",
      "\n",
      "EPOCH:\t27\n",
      "train_roc:[0.7956824988506013]\n",
      "valid_roc:[0.7953935379364206]\n",
      "\n",
      "EPOCH:\t28\n",
      "train_roc:[0.7954753450364771]\n",
      "valid_roc:[0.7970336409129039]\n",
      "\n",
      "EPOCH:\t29\n",
      "train_roc:[0.7945111422998962]\n",
      "valid_roc:[0.792018599404125]\n",
      "\n",
      "EPOCH:\t30\n",
      "train_roc:[0.7981925163301362]\n",
      "valid_roc:[0.7962121431257412]\n",
      "\n",
      "EPOCH:\t31\n",
      "train_roc:[0.7970657983766731]\n",
      "valid_roc:[0.7966388013074542]\n",
      "\n",
      "EPOCH:\t32\n",
      "train_roc:[0.7985531492078546]\n",
      "valid_roc:[0.7957652367591334]\n",
      "\n",
      "EPOCH:\t33\n",
      "train_roc:[0.8004738739507218]\n",
      "valid_roc:[0.7996528882589453]\n",
      "\n",
      "EPOCH:\t34\n",
      "train_roc:[0.8013719772260022]\n",
      "valid_roc:[0.7998568164068149]\n",
      "\n",
      "EPOCH:\t35\n",
      "train_roc:[0.8009369316259581]\n",
      "valid_roc:[0.8007303809551358]\n",
      "\n",
      "EPOCH:\t36\n",
      "train_roc:[0.8019444627175545]\n",
      "valid_roc:[0.8014376211275347]\n",
      "\n",
      "EPOCH:\t37\n",
      "train_roc:[0.7993739933725238]\n",
      "valid_roc:[0.7964826010239796]\n",
      "\n",
      "EPOCH:\t38\n",
      "train_roc:[0.8035373106383716]\n",
      "valid_roc:[0.7981718781637789]\n",
      "\n",
      "EPOCH:\t39\n",
      "train_roc:[0.8046492093004427]\n",
      "valid_roc:[0.8010529056145325]\n",
      "\n",
      "EPOCH:\t40\n",
      "train_roc:[0.8004708920201369]\n",
      "valid_roc:[0.8007766625206097]\n",
      "\n",
      "EPOCH:\t41\n",
      "train_roc:[0.806806590897919]\n",
      "valid_roc:[0.8037806253796533]\n",
      "\n",
      "EPOCH:\t42\n",
      "train_roc:[0.8049898722793949]\n",
      "valid_roc:[0.8007911255098203]\n",
      "\n",
      "EPOCH:\t43\n",
      "train_roc:[0.808456185861384]\n",
      "valid_roc:[0.8057866419831651]\n",
      "\n",
      "EPOCH:\t44\n",
      "train_roc:[0.8084933696321634]\n",
      "valid_roc:[0.8068901680599346]\n",
      "\n",
      "EPOCH:\t45\n",
      "train_roc:[0.808307992947463]\n",
      "valid_roc:[0.8045153452315523]\n",
      "\n",
      "EPOCH:\t46\n",
      "train_roc:[0.8084489569387537]\n",
      "valid_roc:[0.8048407624887912]\n",
      "\n",
      "EPOCH:\t47\n",
      "train_roc:[0.8095362772638817]\n",
      "valid_roc:[0.8048074976136068]\n",
      "\n",
      "EPOCH:\t48\n",
      "train_roc:[0.8103901937495844]\n",
      "valid_roc:[0.8067397529721442]\n",
      "\n",
      "EPOCH:\t49\n",
      "train_roc:[0.811564396688575]\n",
      "valid_roc:[0.8084362616065488]\n",
      "\n",
      "EPOCH:\t50\n",
      "train_roc:[0.8110062786807505]\n",
      "valid_roc:[0.8089829625987099]\n",
      "\n",
      "EPOCH:\t51\n",
      "train_roc:[0.8130638559651624]\n",
      "valid_roc:[0.8093966040901334]\n",
      "\n",
      "EPOCH:\t52\n",
      "train_roc:[0.8135957239476856]\n",
      "valid_roc:[0.8101978536924013]\n",
      "\n",
      "EPOCH:\t53\n",
      "train_roc:[0.8108639140857004]\n",
      "valid_roc:[0.8055653582482427]\n",
      "\n",
      "EPOCH:\t54\n",
      "train_roc:[0.8128048346311659]\n",
      "valid_roc:[0.8100474386046108]\n",
      "\n",
      "EPOCH:\t55\n",
      "train_roc:[0.815056915115099]\n",
      "valid_roc:[0.8110685256428798]\n",
      "\n",
      "EPOCH:\t56\n",
      "train_roc:[0.815399611228541]\n",
      "valid_roc:[0.8106057099881404]\n",
      "\n",
      "EPOCH:\t57\n",
      "train_roc:[0.8130192173679203]\n",
      "valid_roc:[0.8072083538225681]\n",
      "\n",
      "EPOCH:\t58\n",
      "train_roc:[0.8161783469188886]\n",
      "valid_roc:[0.8114850597321455]\n",
      "\n",
      "EPOCH:\t59\n",
      "train_roc:[0.8155595059609697]\n",
      "valid_roc:[0.8109918718000637]\n",
      "\n",
      "EPOCH:\t60\n",
      "train_roc:[0.8156658163044013]\n",
      "valid_roc:[0.8118495270602528]\n",
      "\n",
      "EPOCH:\t61\n",
      "train_roc:[0.8173757275910627]\n",
      "valid_roc:[0.8118256631280554]\n",
      "\n",
      "EPOCH:\t62\n",
      "train_roc:[0.815451659471479]\n",
      "valid_roc:[0.8111046831159064]\n",
      "\n",
      "EPOCH:\t63\n",
      "train_roc:[0.8149855746848912]\n",
      "valid_roc:[0.8091926759422637]\n",
      "\n",
      "EPOCH:\t64\n",
      "train_roc:[0.8180253366509269]\n",
      "valid_roc:[0.8124931300801249]\n",
      "\n",
      "EPOCH:\t65\n",
      "train_roc:[0.8103411274372312]\n",
      "valid_roc:[0.8077926585866767]\n",
      "\n",
      "EPOCH:\t66\n",
      "train_roc:[0.8184050809928491]\n",
      "valid_roc:[0.8123600705793873]\n",
      "\n",
      "EPOCH:\t67\n",
      "train_roc:[0.8071641514835196]\n",
      "valid_roc:[0.8051589482514245]\n",
      "\n",
      "EPOCH:\t68\n",
      "train_roc:[0.8166802600532628]\n",
      "valid_roc:[0.8114387781666715]\n",
      "\n",
      "EPOCH:\t69\n",
      "train_roc:[0.8186640119653128]\n",
      "valid_roc:[0.813843973272396]\n",
      "\n",
      "EPOCH:\t70\n",
      "train_roc:[0.8209080954535859]\n",
      "valid_roc:[0.813540250498973]\n",
      "\n",
      "EPOCH:\t71\n",
      "train_roc:[0.8150232554441016]\n",
      "valid_roc:[0.8082395649532846]\n",
      "\n",
      "EPOCH:\t72\n",
      "train_roc:[0.8188698555372101]\n",
      "valid_roc:[0.8137326082554742]\n",
      "\n",
      "EPOCH:\t73\n",
      "train_roc:[0.817897610624203]\n",
      "valid_roc:[0.8117699806195946]\n",
      "\n",
      "EPOCH:\t74\n",
      "train_roc:[0.8214161531721959]\n",
      "valid_roc:[0.815122501518614]\n",
      "\n",
      "EPOCH:\t75\n",
      "train_roc:[0.8191852172869565]\n",
      "valid_roc:[0.81170923606491]\n",
      "\n",
      "EPOCH:\t76\n",
      "train_roc:[0.8113541705823331]\n",
      "valid_roc:[0.8073124873448845]\n",
      "\n",
      "EPOCH:\t77\n",
      "train_roc:[0.8209728394918934]\n",
      "valid_roc:[0.8135315727054468]\n",
      "\n",
      "EPOCH:\t78\n",
      "train_roc:[0.8208342700812241]\n",
      "valid_roc:[0.8153437852535361]\n",
      "\n",
      "EPOCH:\t79\n",
      "train_roc:[0.8117668517029896]\n",
      "valid_roc:[0.8037806253796536]\n",
      "\n",
      "EPOCH:\t80\n",
      "train_roc:[0.8207898573878143]\n",
      "valid_roc:[0.8145251800642157]\n",
      "\n",
      "EPOCH:\t81\n",
      "train_roc:[0.81817045727273]\n",
      "valid_roc:[0.8099548754736628]\n",
      "\n",
      "EPOCH:\t82\n",
      "train_roc:[0.8235977968412499]\n",
      "valid_roc:[0.8160481328280929]\n",
      "\n",
      "EPOCH:\t83\n",
      "train_roc:[0.8234015315918376]\n",
      "valid_roc:[0.8134607040583148]\n",
      "\n",
      "EPOCH:\t84\n",
      "train_roc:[0.8239413062084879]\n",
      "valid_roc:[0.8170012438170722]\n",
      "\n",
      "EPOCH:\t85\n",
      "train_roc:[0.8142187215361172]\n",
      "valid_roc:[0.8048523328801598]\n",
      "\n",
      "EPOCH:\t86\n",
      "train_roc:[0.8218528252798315]\n",
      "valid_roc:[0.8128662752017587]\n",
      "\n",
      "EPOCH:\t87\n",
      "train_roc:[0.8252582803694268]\n",
      "valid_roc:[0.8154739521564318]\n",
      "\n",
      "EPOCH:\t88\n",
      "train_roc:[0.826237121674334]\n",
      "valid_roc:[0.8177200543808394]\n",
      "\n",
      "EPOCH:\t89\n",
      "train_roc:[0.8223836089239605]\n",
      "valid_roc:[0.8131063608226549]\n",
      "\n",
      "EPOCH:\t90\n",
      "train_roc:[0.8206088632374586]\n",
      "valid_roc:[0.8139784790720546]\n",
      "\n",
      "EPOCH:\t91\n",
      "train_roc:[0.8275387795554503]\n",
      "valid_roc:[0.8187946544791879]\n",
      "\n",
      "EPOCH:\t92\n",
      "train_roc:[0.8223400094843465]\n",
      "valid_roc:[0.810926788348616]\n",
      "\n",
      "EPOCH:\t93\n",
      "train_roc:[0.8275133879647113]\n",
      "valid_roc:[0.8163489630036737]\n",
      "\n",
      "EPOCH:\t94\n",
      "train_roc:[0.8281085542010161]\n",
      "valid_roc:[0.8180743976164994]\n",
      "\n",
      "EPOCH:\t95\n",
      "train_roc:[0.8235385196756816]\n",
      "valid_roc:[0.8113751410141447]\n",
      "\n",
      "EPOCH:\t96\n",
      "train_roc:[0.828203478991305]\n",
      "valid_roc:[0.8193254461832172]\n",
      "\n",
      "EPOCH:\t97\n",
      "train_roc:[0.827838147313877]\n",
      "valid_roc:[0.8141448034479766]\n",
      "\n",
      "EPOCH:\t98\n",
      "train_roc:[0.8270860682757284]\n",
      "valid_roc:[0.8170576494749934]\n",
      "\n",
      "EPOCH:\t99\n",
      "train_roc:[0.8252976328169953]\n",
      "valid_roc:[0.8145309652598999]\n",
      "\n",
      "EPOCH:\t100\n",
      "train_roc:[0.8298069895730019]\n",
      "valid_roc:[0.8185372132712387]\n",
      "\n",
      "EPOCH:\t101\n",
      "train_roc:[0.8247226623832891]\n",
      "valid_roc:[0.811001995892511]\n",
      "\n",
      "EPOCH:\t102\n",
      "train_roc:[0.830365152761593]\n",
      "valid_roc:[0.8178400971912875]\n",
      "\n",
      "EPOCH:\t103\n",
      "train_roc:[0.830956523813517]\n",
      "valid_roc:[0.8194729686731654]\n",
      "\n",
      "EPOCH:\t104\n",
      "train_roc:[0.831793000523374]\n",
      "valid_roc:[0.8196956987070088]\n",
      "\n",
      "EPOCH:\t105\n",
      "train_roc:[0.8303908154369305]\n",
      "valid_roc:[0.8182493997859477]\n",
      "\n",
      "EPOCH:\t106\n",
      "train_roc:[0.8325524892072185]\n",
      "valid_roc:[0.8184388649446068]\n",
      "\n",
      "EPOCH:\t107\n",
      "train_roc:[0.8319248379998438]\n",
      "valid_roc:[0.8198142952185358]\n",
      "\n",
      "EPOCH:\t108\n",
      "train_roc:[0.8312069156211236]\n",
      "valid_roc:[0.8182696479708426]\n",
      "\n",
      "EPOCH:\t109\n",
      "train_roc:[0.8321537689433918]\n",
      "valid_roc:[0.8184721298197911]\n",
      "\n",
      "EPOCH:\t110\n",
      "train_roc:[0.8337721891780137]\n",
      "valid_roc:[0.8198851638656677]\n",
      "\n",
      "EPOCH:\t111\n",
      "train_roc:[0.8318579704655137]\n",
      "valid_roc:[0.8163070203349629]\n",
      "\n",
      "EPOCH:\t112\n",
      "train_roc:[0.8315402141351462]\n",
      "valid_roc:[0.8195698707008764]\n",
      "\n",
      "EPOCH:\t113\n",
      "train_roc:[0.8319309374033133]\n",
      "valid_roc:[0.8164357409389372]\n",
      "\n",
      "EPOCH:\t114\n",
      "train_roc:[0.8338535145576044]\n",
      "valid_roc:[0.8191244106331896]\n",
      "\n",
      "EPOCH:\t115\n",
      "train_roc:[0.8326747483612033]\n",
      "valid_roc:[0.8175826559833388]\n",
      "\n",
      "EPOCH:\t116\n",
      "train_roc:[0.8338943579704655]\n",
      "valid_roc:[0.8173179832807844]\n",
      "\n",
      "EPOCH:\t117\n",
      "train_roc:[0.834341692738981]\n",
      "valid_roc:[0.8217740302565735]\n",
      "\n",
      "EPOCH:\t118\n",
      "train_roc:[0.8345261658083525]\n",
      "valid_roc:[0.8187527118104772]\n",
      "\n",
      "EPOCH:\t119\n",
      "train_roc:[0.8354003232774201]\n",
      "valid_roc:[0.8178834861589193]\n",
      "\n",
      "EPOCH:\t120\n",
      "train_roc:[0.8358624321565611]\n",
      "valid_roc:[0.820742819125857]\n",
      "\n",
      "EPOCH:\t121\n",
      "train_roc:[0.8355907150271953]\n",
      "valid_roc:[0.8195568540105869]\n",
      "\n",
      "EPOCH:\t122\n",
      "train_roc:[0.8360252636388082]\n",
      "valid_roc:[0.8180584883283677]\n",
      "\n",
      "EPOCH:\t123\n",
      "train_roc:[0.8348806541018353]\n",
      "valid_roc:[0.823518266755373]\n",
      "\n",
      "EPOCH:\t124\n",
      "train_roc:[0.8338039512568205]\n",
      "valid_roc:[0.8209684417575424]\n",
      "\n",
      "EPOCH:\t125\n",
      "train_roc:[0.8112636735071552]\n",
      "valid_roc:[0.7969049203089296]\n",
      "\n",
      "EPOCH:\t126\n",
      "train_roc:[0.8334387099409252]\n",
      "valid_roc:[0.8138483121691591]\n",
      "\n",
      "EPOCH:\t127\n",
      "train_roc:[0.8376815453557063]\n",
      "valid_roc:[0.8225564779728675]\n",
      "\n",
      "EPOCH:\t128\n",
      "train_roc:[0.837746605659379]\n",
      "valid_roc:[0.8210653437852535]\n",
      "\n",
      "EPOCH:\t129\n",
      "train_roc:[0.8348068287294734]\n",
      "valid_roc:[0.8164126001562003]\n",
      "\n",
      "EPOCH:\t130\n",
      "train_roc:[0.8367251588917195]\n",
      "valid_roc:[0.8201440513725377]\n",
      "\n",
      "EPOCH:\t131\n",
      "train_roc:[0.8387622241081678]\n",
      "valid_roc:[0.8234170258308986]\n",
      "\n",
      "EPOCH:\t132\n",
      "train_roc:[0.8376823134287359]\n",
      "valid_roc:[0.8216684504353361]\n",
      "\n",
      "EPOCH:\t133\n",
      "train_roc:[0.8383203110316251]\n",
      "valid_roc:[0.8183332851233693]\n",
      "\n",
      "EPOCH:\t134\n",
      "train_roc:[0.8386597541298835]\n",
      "valid_roc:[0.82055624656504]\n",
      "\n",
      "EPOCH:\t135\n",
      "train_roc:[0.8368627795062935]\n",
      "valid_roc:[0.8207370339301727]\n",
      "\n",
      "EPOCH:\t136\n",
      "train_roc:[0.8360240889388809]\n",
      "valid_roc:[0.8210393104046745]\n",
      "\n",
      "EPOCH:\t137\n",
      "train_roc:[0.8383584887792661]\n",
      "valid_roc:[0.8208498452460153]\n",
      "\n",
      "EPOCH:\t138\n",
      "train_roc:[0.8400860657456056]\n",
      "valid_roc:[0.8208686471319893]\n",
      "\n",
      "EPOCH:\t139\n",
      "train_roc:[0.839787149794843]\n",
      "valid_roc:[0.82209655491597]\n",
      "\n",
      "EPOCH:\t140\n",
      "train_roc:[0.8368630957716586]\n",
      "valid_roc:[0.8199010731537995]\n",
      "\n",
      "EPOCH:\t141\n",
      "train_roc:[0.8406754036630397]\n",
      "valid_roc:[0.8246955540771168]\n",
      "\n",
      "EPOCH:\t142\n",
      "train_roc:[0.8390756882657237]\n",
      "valid_roc:[0.8184880391079228]\n",
      "\n",
      "EPOCH:\t143\n",
      "train_roc:[0.8422433118007824]\n",
      "valid_roc:[0.8244945185270891]\n",
      "\n",
      "EPOCH:\t144\n",
      "train_roc:[0.8408380092414547]\n",
      "valid_roc:[0.8254953573804633]\n",
      "\n",
      "EPOCH:\t145\n",
      "train_roc:[0.8373625239638787]\n",
      "valid_roc:[0.816667148766307]\n",
      "\n",
      "EPOCH:\t146\n",
      "train_roc:[0.8394543030884849]\n",
      "valid_roc:[0.8214717537820717]\n",
      "\n",
      "EPOCH:\t147\n",
      "train_roc:[0.8377842412378228]\n",
      "valid_roc:[0.8205128575974082]\n",
      "\n",
      "EPOCH:\t148\n",
      "train_roc:[0.8394791976907929]\n",
      "valid_roc:[0.8196392930490873]\n",
      "\n",
      "EPOCH:\t149\n",
      "train_roc:[0.8369475838049]\n",
      "valid_roc:[0.8185299817766336]\n",
      "\n",
      "EPOCH:\t150\n",
      "train_roc:[0.8425078451882845]\n",
      "valid_roc:[0.8228905730236326]\n",
      "\n",
      "EPOCH:\t151\n",
      "train_roc:[0.8348665577027061]\n",
      "valid_roc:[0.8127823898643373]\n",
      "\n",
      "EPOCH:\t152\n",
      "train_roc:[0.8424598180335595]\n",
      "valid_roc:[0.8252625032541726]\n",
      "\n",
      "EPOCH:\t153\n",
      "train_roc:[0.8432447886696759]\n",
      "valid_roc:[0.8243151774608777]\n",
      "\n",
      "EPOCH:\t154\n",
      "train_roc:[0.8404047708720683]\n",
      "valid_roc:[0.8210335252089902]\n",
      "\n",
      "EPOCH:\t155\n",
      "train_roc:[0.8414306001740723]\n",
      "valid_roc:[0.8206921986636198]\n",
      "\n",
      "EPOCH:\t156\n",
      "train_roc:[0.8360127937472712]\n",
      "valid_roc:[0.8202120274218276]\n",
      "\n",
      "EPOCH:\t157\n",
      "train_roc:[0.8419756609403961]\n",
      "valid_roc:[0.8247201411587746]\n",
      "\n",
      "EPOCH:\t158\n",
      "train_roc:[0.8416183262586276]\n",
      "valid_roc:[0.8227705302131844]\n",
      "\n",
      "EPOCH:\t159\n",
      "train_roc:[0.8395958996105055]\n",
      "valid_roc:[0.8199994214804316]\n",
      "\n",
      "EPOCH:\t160\n",
      "train_roc:[0.8441931329572365]\n",
      "valid_roc:[0.8260825547424143]\n",
      "\n",
      "EPOCH:\t161\n",
      "train_roc:[0.8440962653939907]\n",
      "valid_roc:[0.8262170605420729]\n",
      "\n",
      "EPOCH:\t162\n",
      "train_roc:[0.8454239022158093]\n",
      "valid_roc:[0.8243093922651934]\n",
      "\n",
      "EPOCH:\t163\n",
      "train_roc:[0.8431927404267379]\n",
      "valid_roc:[0.8237193023054006]\n",
      "\n",
      "EPOCH:\t164\n",
      "train_roc:[0.8414535068226572]\n",
      "valid_roc:[0.8206994301582252]\n",
      "\n",
      "EPOCH:\t165\n",
      "train_roc:[0.8443728620461322]\n",
      "valid_roc:[0.8223004830638398]\n",
      "\n",
      "EPOCH:\t166\n",
      "train_roc:[0.8424903602316726]\n",
      "valid_roc:[0.8189146972896358]\n",
      "\n",
      "EPOCH:\t167\n",
      "train_roc:[0.8429981016849173]\n",
      "valid_roc:[0.823257932949582]\n",
      "\n",
      "EPOCH:\t168\n",
      "train_roc:[0.8457925320891876]\n",
      "valid_roc:[0.822498626016025]\n",
      "\n",
      "EPOCH:\t169\n",
      "train_roc:[0.8437140361099144]\n",
      "valid_roc:[0.8174322408955483]\n",
      "\n",
      "EPOCH:\t170\n",
      "train_roc:[0.8440205424294385]\n",
      "valid_roc:[0.8250961788782506]\n",
      "\n",
      "EPOCH:\t171\n",
      "train_roc:[0.8429031317138619]\n",
      "valid_roc:[0.8240085620896126]\n",
      "\n",
      "EPOCH:\t172\n",
      "train_roc:[0.8426896074116698]\n",
      "valid_roc:[0.8210798067744642]\n",
      "\n",
      "EPOCH:\t173\n",
      "train_roc:[0.8447091424907397]\n",
      "valid_roc:[0.8222787885800238]\n",
      "\n",
      "EPOCH:\t174\n",
      "train_roc:[0.8446575912362324]\n",
      "valid_roc:[0.822738711636921]\n",
      "\n",
      "EPOCH:\t175\n",
      "train_roc:[0.848080847547805]\n",
      "valid_roc:[0.8244236498799572]\n",
      "\n",
      "EPOCH:\t176\n",
      "train_roc:[0.8472914943773439]\n",
      "valid_roc:[0.8247606375285644]\n",
      "\n",
      "EPOCH:\t177\n",
      "train_roc:[0.8435578010195672]\n",
      "valid_roc:[0.8220010991871799]\n",
      "\n",
      "EPOCH:\t178\n",
      "train_roc:[0.8406805994511803]\n",
      "valid_roc:[0.8186847357611872]\n",
      "\n",
      "EPOCH:\t179\n",
      "train_roc:[0.8455681192222835]\n",
      "valid_roc:[0.8232521477538978]\n",
      "\n",
      "EPOCH:\t180\n",
      "train_roc:[0.8464248369155056]\n",
      "valid_roc:[0.8226880911746841]\n",
      "\n",
      "EPOCH:\t181\n",
      "train_roc:[0.8440966720208889]\n",
      "valid_roc:[0.8211260883399382]\n",
      "\n",
      "EPOCH:\t182\n",
      "train_roc:[0.8419294861970952]\n",
      "valid_roc:[0.8232695033409505]\n",
      "\n",
      "EPOCH:\t183\n",
      "train_roc:[0.8438784037382205]\n",
      "valid_roc:[0.8188134563651615]\n",
      "\n",
      "EPOCH:\t184\n",
      "train_roc:[0.8466600931663548]\n",
      "valid_roc:[0.8213574961673078]\n",
      "\n",
      "EPOCH:\t185\n",
      "train_roc:[0.8454989022880985]\n",
      "valid_roc:[0.8221587457695757]\n",
      "\n",
      "EPOCH:\t186\n",
      "train_roc:[0.8482056368247102]\n",
      "valid_roc:[0.8244728240432733]\n",
      "\n",
      "EPOCH:\t187\n",
      "train_roc:[0.8440611147577011]\n",
      "valid_roc:[0.8185834948367129]\n",
      "\n",
      "EPOCH:\t188\n",
      "train_roc:[0.8481019921464985]\n",
      "valid_roc:[0.823234792166845]\n",
      "\n",
      "EPOCH:\t189\n",
      "train_roc:[0.8482059530900752]\n",
      "valid_roc:[0.8264549767145875]\n",
      "\n",
      "EPOCH:\t190\n",
      "train_roc:[0.8482632874826868]\n",
      "valid_roc:[0.8240432732637181]\n",
      "\n",
      "EPOCH:\t191\n",
      "train_roc:[0.8485905769547729]\n",
      "valid_roc:[0.8242443088137456]\n",
      "\n",
      "EPOCH:\t192\n",
      "train_roc:[0.8415278291834498]\n",
      "valid_roc:[0.8194932168580603]\n",
      "\n",
      "EPOCH:\t193\n",
      "train_roc:[0.8432580718150091]\n",
      "valid_roc:[0.8177909230279713]\n",
      "\n",
      "EPOCH:\t194\n",
      "train_roc:[0.8492550053060292]\n",
      "valid_roc:[0.8243180700587197]\n",
      "\n",
      "EPOCH:\t195\n",
      "train_roc:[0.8457290982931068]\n",
      "valid_roc:[0.8201845477423274]\n",
      "\n",
      "EPOCH:\t196\n",
      "train_roc:[0.8471837382493863]\n",
      "valid_roc:[0.8234546296028464]\n",
      "\n",
      "EPOCH:\t197\n",
      "train_roc:[0.848237805530415]\n",
      "valid_roc:[0.8238841803824013]\n",
      "\n",
      "EPOCH:\t198\n",
      "train_roc:[0.8470403344967079]\n",
      "valid_roc:[0.8214862167712822]\n",
      "\n",
      "EPOCH:\t199\n",
      "train_roc:[0.8463971862864447]\n",
      "valid_roc:[0.8229252841977379]\n",
      "\n",
      "EPOCH:\t200\n",
      "train_roc:[0.8471221568647295]\n",
      "valid_roc:[0.8176477394347865]\n",
      "\n",
      "EPOCH:\t201\n",
      "train_roc:[0.8499970993947946]\n",
      "valid_roc:[0.8236874837291371]\n",
      "\n",
      "EPOCH:\t202\n",
      "train_roc:[0.8488511344348283]\n",
      "valid_roc:[0.8247360504469063]\n",
      "\n",
      "EPOCH:\t203\n",
      "train_roc:[0.8480515704111522]\n",
      "valid_roc:[0.8273726533800007]\n",
      "\n",
      "EPOCH:\t204\n",
      "train_roc:[0.8506525367735294]\n",
      "valid_roc:[0.8262806976945994]\n",
      "\n",
      "EPOCH:\t205\n",
      "train_roc:[0.8480027751833977]\n",
      "valid_roc:[0.8242182754331665]\n",
      "\n",
      "EPOCH:\t206\n",
      "train_roc:[0.8465823822480792]\n",
      "valid_roc:[0.8211275346388591]\n",
      "\n",
      "EPOCH:\t207\n",
      "train_roc:[0.8503347352623956]\n",
      "valid_roc:[0.8274391831303695]\n",
      "\n",
      "EPOCH:\t208\n",
      "train_roc:[0.8487228210581408]\n",
      "valid_roc:[0.8244178646842729]\n",
      "\n",
      "EPOCH:\t209\n",
      "train_roc:[0.8515238930350776]\n",
      "valid_roc:[0.8263067310751786]\n",
      "\n",
      "EPOCH:\t210\n",
      "train_roc:[0.850401241350594]\n",
      "valid_roc:[0.8253463885915941]\n",
      "\n",
      "EPOCH:\t211\n",
      "train_roc:[0.8486637246156382]\n",
      "valid_roc:[0.8239738509155073]\n",
      "\n",
      "EPOCH:\t212\n",
      "train_roc:[0.8502054279088462]\n",
      "valid_roc:[0.8254317202279368]\n",
      "\n",
      "EPOCH:\t213\n",
      "train_roc:[0.8478000039036182]\n",
      "valid_roc:[0.8256587891585432]\n",
      "\n",
      "EPOCH:\t214\n",
      "train_roc:[0.8498559546804382]\n",
      "valid_roc:[0.823234792166845]\n",
      "\n",
      "EPOCH:\t215\n",
      "train_roc:[0.8516156099909494]\n",
      "valid_roc:[0.824656504006248]\n",
      "\n",
      "EPOCH:\t216\n",
      "train_roc:[0.8509517238088903]\n",
      "valid_roc:[0.8271065343785254]\n",
      "\n",
      "EPOCH:\t217\n",
      "train_roc:[0.851304043425584]\n",
      "valid_roc:[0.8243368719446936]\n",
      "\n",
      "EPOCH:\t218\n",
      "train_roc:[0.8512161216540931]\n",
      "valid_roc:[0.8248879118336176]\n",
      "\n",
      "EPOCH:\t219\n",
      "train_roc:[0.8504436209095141]\n",
      "valid_roc:[0.8235833502068206]\n",
      "\n",
      "EPOCH:\t220\n",
      "train_roc:[0.8498181383789285]\n",
      "valid_roc:[0.821831882213416]\n",
      "\n",
      "EPOCH:\t221\n",
      "train_roc:[0.8503080786101963]\n",
      "valid_roc:[0.8268404153770501]\n",
      "\n",
      "EPOCH:\t222\n",
      "train_roc:[0.8454183449815373]\n",
      "valid_roc:[0.8211636921118857]\n",
      "\n",
      "EPOCH:\t223\n",
      "train_roc:[0.8481956066945606]\n",
      "valid_roc:[0.8242833588846143]\n",
      "\n",
      "EPOCH:\t224\n",
      "train_roc:[0.8515222213467195]\n",
      "valid_roc:[0.8257600300830177]\n",
      "\n",
      "EPOCH:\t225\n",
      "train_roc:[0.8512352782990635]\n",
      "valid_roc:[0.8263877238147579]\n",
      "\n",
      "EPOCH:\t226\n",
      "train_roc:[0.8511094046837636]\n",
      "valid_roc:[0.8273393885048161]\n",
      "\n",
      "EPOCH:\t227\n",
      "train_roc:[0.8501741628184702]\n",
      "valid_roc:[0.8237945098492957]\n",
      "\n",
      "EPOCH:\t228\n",
      "train_roc:[0.8495677465713221]\n",
      "valid_roc:[0.8287567614474559]\n",
      "\n",
      "EPOCH:\t229\n",
      "train_roc:[0.8529990450593206]\n",
      "valid_roc:[0.8255662260275953]\n",
      "\n",
      "EPOCH:\t230\n",
      "train_roc:[0.8512866036497384]\n",
      "valid_roc:[0.8261028029273091]\n",
      "\n",
      "EPOCH:\t231\n",
      "train_roc:[0.852191935847649]\n",
      "valid_roc:[0.8257556911862544]\n",
      "\n",
      "EPOCH:\t232\n",
      "train_roc:[0.8517746462888157]\n",
      "valid_roc:[0.8250658066009083]\n",
      "\n",
      "EPOCH:\t233\n",
      "train_roc:[0.8529605510463143]\n",
      "valid_roc:[0.8241271586011397]\n",
      "\n",
      "EPOCH:\t234\n",
      "train_roc:[0.8532172681612223]\n",
      "valid_roc:[0.8262373087269677]\n",
      "\n",
      "EPOCH:\t235\n",
      "train_roc:[0.8534757925067878]\n",
      "valid_roc:[0.8277342281102656]\n",
      "\n",
      "EPOCH:\t236\n",
      "train_roc:[0.8496867075293566]\n",
      "valid_roc:[0.8219244453443637]\n",
      "\n",
      "EPOCH:\t237\n",
      "train_roc:[0.8493769481946488]\n",
      "valid_roc:[0.8210234011165428]\n",
      "\n",
      "EPOCH:\t238\n",
      "train_roc:[0.8523900083277188]\n",
      "valid_roc:[0.8276821613491077]\n",
      "\n",
      "EPOCH:\t239\n",
      "train_roc:[0.852095158645936]\n",
      "valid_roc:[0.8269069451274189]\n",
      "\n",
      "EPOCH:\t240\n",
      "train_roc:[0.848730456607669]\n",
      "valid_roc:[0.8276156315987389]\n",
      "\n",
      "EPOCH:\t241\n",
      "train_roc:[0.8528597527563881]\n",
      "valid_roc:[0.8248170431864859]\n",
      "\n",
      "EPOCH:\t242\n",
      "train_roc:[0.8520544959561406]\n",
      "valid_roc:[0.8263964016082845]\n",
      "\n",
      "EPOCH:\t243\n",
      "train_roc:[0.854385281335211]\n",
      "valid_roc:[0.82629516068381]\n",
      "\n",
      "EPOCH:\t244\n",
      "train_roc:[0.8540696485008661]\n",
      "valid_roc:[0.826151977090625]\n",
      "\n",
      "EPOCH:\t245\n",
      "train_roc:[0.8553548605829983]\n",
      "valid_roc:[0.8258844117902288]\n",
      "\n",
      "EPOCH:\t246\n",
      "train_roc:[0.8500763012783626]\n",
      "valid_roc:[0.8204564519394868]\n",
      "\n",
      "EPOCH:\t247\n",
      "train_roc:[0.848686631264223]\n",
      "valid_roc:[0.8237424430881376]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_param ={}\n",
    "best_param[\"roc_epoch\"] = 0\n",
    "best_param[\"loss_epoch\"] = 0\n",
    "best_param[\"valid_roc\"] = 0\n",
    "best_param[\"valid_loss\"] = 9e8\n",
    "\n",
    "for epoch in range(epochs):    \n",
    "    train_roc, train_prc, train_precision, train_recall, train_loss = eval(model, train_df)\n",
    "    valid_roc, valid_prc, valid_precision, valid_recall, valid_loss = eval(model, valid_df)\n",
    "    train_roc_mean = np.array(train_roc).mean()\n",
    "    valid_roc_mean = np.array(valid_roc).mean()\n",
    "    \n",
    "#     tensorboard.add_scalars('ROC',{'train_roc':train_roc_mean,'valid_roc':valid_roc_mean},epoch)\n",
    "#     tensorboard.add_scalars('Losses',{'train_losses':train_loss,'valid_losses':valid_loss},epoch)\n",
    "\n",
    "    if valid_roc_mean > best_param[\"valid_roc\"]:\n",
    "        best_param[\"roc_epoch\"] = epoch\n",
    "        best_param[\"valid_roc\"] = valid_roc_mean\n",
    "        if valid_roc_mean > 0.81:\n",
    "             torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')             \n",
    "    if valid_loss < best_param[\"valid_loss\"]:\n",
    "        best_param[\"loss_epoch\"] = epoch\n",
    "        best_param[\"valid_loss\"] = valid_loss\n",
    "\n",
    "    print(\"EPOCH:\\t\"+str(epoch)+'\\n'\\\n",
    "        +\"train_roc\"+\":\"+str(train_roc)+'\\n'\\\n",
    "        +\"valid_roc\"+\":\"+str(valid_roc)+'\\n'\\\n",
    "#         +\"train_roc_mean\"+\":\"+str(train_roc_mean)+'\\n'\\\n",
    "#         +\"valid_roc_mean\"+\":\"+str(valid_roc_mean)+'\\n'\\\n",
    "        )\n",
    "    if (epoch - best_param[\"roc_epoch\"] >18) and (epoch - best_param[\"loss_epoch\"] >28):        \n",
    "        break\n",
    "        \n",
    "    train(model, train_df, optimizer, loss_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where((y_val=='0') | (y_val=='1'))[0]\n",
    "#             print(validInds)\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "#             print(validInds)\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "#             print(y_pred_adjust)\n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            #a=list(y_val_list[0].values())\n",
    "            #b=list(y_pred_list[0].values())\n",
    "            #print(len(a[0]))\n",
    "            #print(len(b[0]))\n",
    "            try:\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                y_val_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)  \n",
    "            #c=list(y_val_list[0].values())\n",
    "            #d=list(y_pred_list[0].values())\n",
    "            #print(len(c[0]))\n",
    "            #print(len(d[0]))          \n",
    "    test_roc = [roc_auc_score(y_val_list[i], y_pred_list[i]) for i in range(len(tasks))]\n",
    "    test_prc = [auc(precision_recall_curve(y_val_list[i], y_pred_list[i])[1],precision_recall_curve(y_val_list[i], y_pred_list[i])[0]) for i in range(len(tasks))]\n",
    "#     test_prc = auc(recall, precision)\n",
    "    test_precision = [precision_score(y_val_list[i],\n",
    "                                     (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_recall = [recall_score(y_val_list[i],\n",
    "                               (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_loss = np.array(losses_list).mean()\n",
    "    \n",
    "    return test_roc, test_prc, test_precision, test_recall, test_loss, y_val_list, y_pred_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=list(y_val_list[0].values())\n",
    "b=list(y_pred_list[0].values())\n",
    "print(len(a[0]))\n",
    "print(len(b[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch:228\n",
      "test_roc:[0.8070422991501294]\n",
      "test_roc_mean: 0.8070422991501294\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"roc_epoch\"])+'.pt')     \n",
    "\n",
    "# best_model_dict = best_model.state_dict()\n",
    "# best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "# model.load_state_dict(best_model_wts)\n",
    "# (best_model.align[0].weight == model.align[0].weight).all()\n",
    "\n",
    "test_roc, test_prc, test_precision, test_recall, test_loss, y_val_list, y_pred_list= pred(best_model, test_df)\n",
    "\n",
    "print(\"best epoch:\"+str(best_param[\"roc_epoch\"])\n",
    "      +\"\\n\"+\"test_roc:\"+str(test_roc)\n",
    "      +\"\\n\"+\"test_roc_mean:\",str(np.array(test_roc).mean())\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2603\n",
      "2603\n"
     ]
    }
   ],
   "source": [
    "a=list(y_val_list[0])\n",
    "b=list(y_pred_list[0])\n",
    "print(len(a))\n",
    "print(len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_epoch': 228,\n",
       " 'loss_epoch': 216,\n",
       " 'valid_roc': 0.8287567614474559,\n",
       " 'valid_loss': 0.5109517}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7300445993081528"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score  \n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "y_pred_final=list(map(lambda x: 0 if x<=0.5 else 1,list(y_pred_list[0])))\n",
    "y_true=list(y_val_list[0])\n",
    "balanced_accuracy_score(y_true,y_pred_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
