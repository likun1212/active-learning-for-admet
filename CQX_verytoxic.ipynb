{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "torch.manual_seed(8) # for reproduce\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "# from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from IPython.display import SVG, display\n",
    "import seaborn as sns; sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  11070\n",
      "number of successfully processed smiles:  11070\n"
     ]
    }
   ],
   "source": [
    "task_name = 'verytoxic'\n",
    "tasks = ['verytoxic']\n",
    "raw_filename = \"../data/verytoxic/total_verytoxic_1.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(\"not successfully processed smiles: \", smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)]\n",
    "# print(smiles_tasks_df)\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "assert canonical_smiles_list[8]==Chem.MolToSmiles(Chem.MolFromSmiles(smiles_tasks_df['cano_smiles'][8]), isomericSmiles=True)\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# print(len([i for i in atom_num_dist if i<51]),len([i for i in atom_num_dist if i>50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 188\n",
    "random_seed = int(time.time())\n",
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 800\n",
    "p_dropout = 0.1\n",
    "fingerprint_dim = 150\n",
    "\n",
    "radius = 3\n",
    "T = 2\n",
    "weight_decay = 2.9 # also known as l2_regularization_lambda\n",
    "learning_rate = 3.5\n",
    "per_task_output_units_num = 2 # for classification model with 2 classes\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n",
      "feature dicts file saved as ../data/verytoxic/total_verytoxic_1.pickle\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verytoxic</th>\n",
       "      <th>smiles</th>\n",
       "      <th>cano_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7888</th>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      verytoxic smiles cano_smiles\n",
       "7888          0      C           C"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smilesList = [smiles for smiles in canonical_smiles_list if len(Chem.MolFromSmiles(smiles).GetAtoms())<101]\n",
    "uncovered = [smiles for smiles in canonical_smiles_list if len(Chem.MolFromSmiles(smiles).GetAtoms())>100]\n",
    "\n",
    "smiles_tasks_df = smiles_tasks_df[~smiles_tasks_df[\"cano_smiles\"].isin(uncovered)]\n",
    "\n",
    "if os.path.isfile(feature_filename):\n",
    "    feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "else:\n",
    "    feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "# feature_dicts = get_smiles_dicts(smilesList)\n",
    "\n",
    "remained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = smiles_tasks_df.drop(remained_df.index)\n",
    "uncovered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for i,task in enumerate(tasks):    \n",
    "    negative_df = remained_df[remained_df[task] == 0][[\"smiles\",task]]\n",
    "    positive_df = remained_df[remained_df[task] == 1][[\"smiles\",task]]\n",
    "    weights.append([(positive_df.shape[0]+negative_df.shape[0])/negative_df.shape[0],\\\n",
    "                    (positive_df.shape[0]+negative_df.shape[0])/positive_df.shape[0]])\n",
    "    \n",
    "test_df=remained_df.tail(2607)\n",
    "training_data = remained_df.drop(test_df.index) # training data\n",
    "\n",
    "# training data is further divided into validation set and train set\n",
    "valid_df = training_data.sample(frac=1/5, random_state=random_seed) # validation set\n",
    "train_df = training_data.drop(valid_df.index) # train set\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649206\n",
      "atom_fc.weight torch.Size([150, 39])\n",
      "atom_fc.bias torch.Size([150])\n",
      "neighbor_fc.weight torch.Size([150, 49])\n",
      "neighbor_fc.bias torch.Size([150])\n",
      "GRUCell.0.weight_ih torch.Size([450, 150])\n",
      "GRUCell.0.weight_hh torch.Size([450, 150])\n",
      "GRUCell.0.bias_ih torch.Size([450])\n",
      "GRUCell.0.bias_hh torch.Size([450])\n",
      "GRUCell.1.weight_ih torch.Size([450, 150])\n",
      "GRUCell.1.weight_hh torch.Size([450, 150])\n",
      "GRUCell.1.bias_ih torch.Size([450])\n",
      "GRUCell.1.bias_hh torch.Size([450])\n",
      "GRUCell.2.weight_ih torch.Size([450, 150])\n",
      "GRUCell.2.weight_hh torch.Size([450, 150])\n",
      "GRUCell.2.bias_ih torch.Size([450])\n",
      "GRUCell.2.bias_hh torch.Size([450])\n",
      "align.0.weight torch.Size([1, 300])\n",
      "align.0.bias torch.Size([1])\n",
      "align.1.weight torch.Size([1, 300])\n",
      "align.1.bias torch.Size([1])\n",
      "align.2.weight torch.Size([1, 300])\n",
      "align.2.bias torch.Size([1])\n",
      "attend.0.weight torch.Size([150, 150])\n",
      "attend.0.bias torch.Size([150])\n",
      "attend.1.weight torch.Size([150, 150])\n",
      "attend.1.bias torch.Size([150])\n",
      "attend.2.weight torch.Size([150, 150])\n",
      "attend.2.bias torch.Size([150])\n",
      "mol_GRUCell.weight_ih torch.Size([450, 150])\n",
      "mol_GRUCell.weight_hh torch.Size([450, 150])\n",
      "mol_GRUCell.bias_ih torch.Size([450])\n",
      "mol_GRUCell.bias_hh torch.Size([450])\n",
      "mol_align.weight torch.Size([1, 300])\n",
      "mol_align.bias torch.Size([1])\n",
      "mol_attend.weight torch.Size([150, 150])\n",
      "mol_attend.bias torch.Size([150])\n",
      "output.weight torch.Size([2, 150])\n",
      "output.bias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([smilesList[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "\n",
    "loss_function = [nn.CrossEntropyLoss(torch.Tensor(weight),reduction='mean') for weight in weights]\n",
    "model = Fingerprint(radius, T, num_atom_features,num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "model.cuda()\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, optimizer, loss_function):\n",
    "    model.train()\n",
    "    np.random.seed(epoch)\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "#         print(torch.Tensor(x_atom).size(),torch.Tensor(x_bonds).size(),torch.cuda.LongTensor(x_atom_index).size(),torch.cuda.LongTensor(x_bond_index).size(),torch.Tensor(x_mask).size())\n",
    "        \n",
    "        model.zero_grad()\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target wrapped in a variable)\n",
    "        loss = 0.0\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where(y_val != -1)[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "\n",
    "            loss += loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where((y_val=='0') | (y_val=='1'))[0]\n",
    "#             print(validInds)\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "#             print(validInds)\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "#             print(y_pred_adjust)\n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            try:\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                y_val_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)            \n",
    "    test_roc = [roc_auc_score(y_val_list[i], y_pred_list[i]) for i in range(len(tasks))]\n",
    "    test_prc = [auc(precision_recall_curve(y_val_list[i], y_pred_list[i])[1],precision_recall_curve(y_val_list[i], y_pred_list[i])[0]) for i in range(len(tasks))]\n",
    "#     test_prc = auc(recall, precision)\n",
    "    test_precision = [precision_score(y_val_list[i],\n",
    "                                     (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_recall = [recall_score(y_val_list[i],\n",
    "                               (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_loss = np.array(losses_list).mean()\n",
    "    \n",
    "    return test_roc, test_prc, test_precision, test_recall, test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:\t0\n",
      "train_roc:[0.5263668727403373]\n",
      "valid_roc:[0.5267559206856331]\n",
      "\n",
      "EPOCH:\t1\n",
      "train_roc:[0.7285873382444898]\n",
      "valid_roc:[0.7301891576651961]\n",
      "\n",
      "EPOCH:\t2\n",
      "train_roc:[0.749558183538581]\n",
      "valid_roc:[0.7408894974390181]\n",
      "\n",
      "EPOCH:\t3\n",
      "train_roc:[0.7645069955556527]\n",
      "valid_roc:[0.749322987981135]\n",
      "\n",
      "EPOCH:\t4\n",
      "train_roc:[0.7818184160246291]\n",
      "valid_roc:[0.7591612150717583]\n",
      "\n",
      "EPOCH:\t5\n",
      "train_roc:[0.7902806259106206]\n",
      "valid_roc:[0.7701556874080837]\n",
      "\n",
      "EPOCH:\t6\n",
      "train_roc:[0.8080664162643343]\n",
      "valid_roc:[0.787263552918505]\n",
      "\n",
      "EPOCH:\t7\n",
      "train_roc:[0.8202451769828115]\n",
      "valid_roc:[0.7970840306303565]\n",
      "\n",
      "EPOCH:\t8\n",
      "train_roc:[0.8288863256860092]\n",
      "valid_roc:[0.8012373852629444]\n",
      "\n",
      "EPOCH:\t9\n",
      "train_roc:[0.8352754775692212]\n",
      "valid_roc:[0.8065774126477002]\n",
      "\n",
      "EPOCH:\t10\n",
      "train_roc:[0.8359462881116578]\n",
      "valid_roc:[0.8071251077640854]\n",
      "\n",
      "EPOCH:\t11\n",
      "train_roc:[0.8455125140959825]\n",
      "valid_roc:[0.8131751102997111]\n",
      "\n",
      "EPOCH:\t12\n",
      "train_roc:[0.8447471936148806]\n",
      "valid_roc:[0.8104315634667071]\n",
      "\n",
      "EPOCH:\t13\n",
      "train_roc:[0.8497401186708794]\n",
      "valid_roc:[0.8160352959075005]\n",
      "\n",
      "EPOCH:\t14\n",
      "train_roc:[0.8553216656263571]\n",
      "valid_roc:[0.818286931385973]\n",
      "\n",
      "EPOCH:\t15\n",
      "train_roc:[0.8533188950149998]\n",
      "valid_roc:[0.8151326132156802]\n",
      "\n",
      "EPOCH:\t16\n",
      "train_roc:[0.8607595574750643]\n",
      "valid_roc:[0.8210304782189768]\n",
      "\n",
      "EPOCH:\t17\n",
      "train_roc:[0.8536210467892804]\n",
      "valid_roc:[0.8101932146660582]\n",
      "\n",
      "EPOCH:\t18\n",
      "train_roc:[0.8624859390213475]\n",
      "valid_roc:[0.8248744865358284]\n",
      "\n",
      "EPOCH:\t19\n",
      "train_roc:[0.8595324684343806]\n",
      "valid_roc:[0.8215426745778184]\n",
      "\n",
      "EPOCH:\t20\n",
      "train_roc:[0.8668076334907378]\n",
      "valid_roc:[0.8274405395811147]\n",
      "\n",
      "EPOCH:\t21\n",
      "train_roc:[0.8714134178350196]\n",
      "valid_roc:[0.8281200872255186]\n",
      "\n",
      "EPOCH:\t22\n",
      "train_roc:[0.8731461000438806]\n",
      "valid_roc:[0.8273898270703384]\n",
      "\n",
      "EPOCH:\t23\n",
      "train_roc:[0.8764157238775229]\n",
      "valid_roc:[0.8280389472082763]\n",
      "\n",
      "EPOCH:\t24\n",
      "train_roc:[0.8779039403783702]\n",
      "valid_roc:[0.831953953040215]\n",
      "\n",
      "EPOCH:\t25\n",
      "train_roc:[0.8794504030043799]\n",
      "valid_roc:[0.8281099447233633]\n",
      "\n",
      "EPOCH:\t26\n",
      "train_roc:[0.8775148394605177]\n",
      "valid_roc:[0.8271362645164563]\n",
      "\n",
      "EPOCH:\t27\n",
      "train_roc:[0.8792042571196788]\n",
      "valid_roc:[0.8356863938333587]\n",
      "\n",
      "EPOCH:\t28\n",
      "train_roc:[0.8840692087179889]\n",
      "valid_roc:[0.8367057152999644]\n",
      "\n",
      "EPOCH:\t29\n",
      "train_roc:[0.8820944410514209]\n",
      "valid_roc:[0.8315533242050814]\n",
      "\n",
      "EPOCH:\t30\n",
      "train_roc:[0.8853537037954913]\n",
      "valid_roc:[0.8344185810639484]\n",
      "\n",
      "EPOCH:\t31\n",
      "train_roc:[0.8834824070099212]\n",
      "valid_roc:[0.833622394644759]\n",
      "\n",
      "EPOCH:\t32\n",
      "train_roc:[0.8875656564044275]\n",
      "valid_roc:[0.8359196713829301]\n",
      "\n",
      "EPOCH:\t33\n",
      "train_roc:[0.8794884870092939]\n",
      "valid_roc:[0.8361833764389675]\n",
      "\n",
      "EPOCH:\t34\n",
      "train_roc:[0.8867488105049126]\n",
      "valid_roc:[0.8382423043764897]\n",
      "\n",
      "EPOCH:\t35\n",
      "train_roc:[0.8915325535633327]\n",
      "valid_roc:[0.8385212231857598]\n",
      "\n",
      "EPOCH:\t36\n",
      "train_roc:[0.8912945285326205]\n",
      "valid_roc:[0.8345301485876566]\n",
      "\n",
      "EPOCH:\t37\n",
      "train_roc:[0.8934821185795899]\n",
      "valid_roc:[0.8401186672752168]\n",
      "\n",
      "EPOCH:\t38\n",
      "train_roc:[0.8910797459460839]\n",
      "valid_roc:[0.8371874841523405]\n",
      "\n",
      "EPOCH:\t39\n",
      "train_roc:[0.8912990090037868]\n",
      "valid_roc:[0.8408945686900957]\n",
      "\n",
      "EPOCH:\t40\n",
      "train_roc:[0.8920503280124938]\n",
      "valid_roc:[0.8352299812363709]\n",
      "\n",
      "EPOCH:\t41\n",
      "train_roc:[0.8967859060058756]\n",
      "valid_roc:[0.8361681626857345]\n",
      "\n",
      "EPOCH:\t42\n",
      "train_roc:[0.8948285001650772]\n",
      "valid_roc:[0.8364673664993153]\n",
      "\n",
      "EPOCH:\t43\n",
      "train_roc:[0.8911626346626611]\n",
      "valid_roc:[0.838054668086617]\n",
      "\n",
      "EPOCH:\t44\n",
      "train_roc:[0.897310961220682]\n",
      "valid_roc:[0.8398245347127136]\n",
      "\n",
      "EPOCH:\t45\n",
      "train_roc:[0.8976923613287173]\n",
      "valid_roc:[0.8381814493635581]\n",
      "\n",
      "EPOCH:\t46\n",
      "train_roc:[0.8975260238366667]\n",
      "valid_roc:[0.8424260865155434]\n",
      "\n",
      "EPOCH:\t47\n",
      "train_roc:[0.8990964289804715]\n",
      "valid_roc:[0.8409148536944065]\n",
      "\n",
      "EPOCH:\t48\n",
      "train_roc:[0.898509207228232]\n",
      "valid_roc:[0.8457021147116993]\n",
      "\n",
      "EPOCH:\t49\n",
      "train_roc:[0.8933379034139229]\n",
      "valid_roc:[0.8244434301942288]\n",
      "\n",
      "EPOCH:\t50\n",
      "train_roc:[0.8978816612354955]\n",
      "valid_roc:[0.8411734874993662]\n",
      "\n",
      "EPOCH:\t51\n",
      "train_roc:[0.9008765761807511]\n",
      "valid_roc:[0.8445509407170748]\n",
      "\n",
      "EPOCH:\t52\n",
      "train_roc:[0.9008368119991498]\n",
      "valid_roc:[0.8388254982504184]\n",
      "\n",
      "EPOCH:\t53\n",
      "train_roc:[0.9018143948017573]\n",
      "valid_roc:[0.8368477103301384]\n",
      "\n",
      "EPOCH:\t54\n",
      "train_roc:[0.9036274454621648]\n",
      "valid_roc:[0.8425832952989503]\n",
      "\n",
      "EPOCH:\t55\n",
      "train_roc:[0.9028320218154141]\n",
      "valid_roc:[0.8412749125209189]\n",
      "\n",
      "EPOCH:\t56\n",
      "train_roc:[0.8995864805142907]\n",
      "valid_roc:[0.8366347177848775]\n",
      "\n",
      "EPOCH:\t57\n",
      "train_roc:[0.8965204380892694]\n",
      "valid_roc:[0.8427810740909782]\n",
      "\n",
      "EPOCH:\t58\n",
      "train_roc:[0.9066062587141664]\n",
      "valid_roc:[0.8417465388711396]\n",
      "\n",
      "EPOCH:\t59\n",
      "train_roc:[0.90430245644632]\n",
      "valid_roc:[0.8372026979055733]\n",
      "\n",
      "EPOCH:\t60\n",
      "train_roc:[0.9004965762199553]\n",
      "valid_roc:[0.837547542978853]\n",
      "\n",
      "EPOCH:\t61\n",
      "train_roc:[0.9055883516710617]\n",
      "valid_roc:[0.8433744104670622]\n",
      "\n",
      "EPOCH:\t62\n",
      "train_roc:[0.902444741088973]\n",
      "valid_roc:[0.8467822911912368]\n",
      "\n",
      "EPOCH:\t63\n",
      "train_roc:[0.9038194056486979]\n",
      "valid_roc:[0.8396571834271515]\n",
      "\n",
      "EPOCH:\t64\n",
      "train_roc:[0.9063298696490922]\n",
      "valid_roc:[0.8457274709670874]\n",
      "\n",
      "EPOCH:\t65\n",
      "train_roc:[0.8957439164302518]\n",
      "valid_roc:[0.8279882346974999]\n",
      "\n",
      "EPOCH:\t66\n",
      "train_roc:[0.908904460393055]\n",
      "valid_roc:[0.847583548861504]\n",
      "\n",
      "EPOCH:\t67\n",
      "train_roc:[0.90742058434865]\n",
      "valid_roc:[0.8492773467214362]\n",
      "\n",
      "EPOCH:\t68\n",
      "train_roc:[0.9097991544790851]\n",
      "valid_roc:[0.8439423905877581]\n",
      "\n",
      "EPOCH:\t69\n",
      "train_roc:[0.9090231928789633]\n",
      "valid_roc:[0.8405345098635834]\n",
      "\n",
      "EPOCH:\t70\n",
      "train_roc:[0.9066250206871754]\n",
      "valid_roc:[0.8436837567827983]\n",
      "\n",
      "EPOCH:\t71\n",
      "train_roc:[0.9079562806824766]\n",
      "valid_roc:[0.8433794817181398]\n",
      "\n",
      "EPOCH:\t72\n",
      "train_roc:[0.9104076584693647]\n",
      "valid_roc:[0.849520766773163]\n",
      "\n",
      "EPOCH:\t73\n",
      "train_roc:[0.9093697293207355]\n",
      "valid_roc:[0.8461382423043765]\n",
      "\n",
      "EPOCH:\t74\n",
      "train_roc:[0.8986065174613762]\n",
      "valid_roc:[0.848658654089964]\n",
      "\n",
      "EPOCH:\t75\n",
      "train_roc:[0.9085961479709207]\n",
      "valid_roc:[0.8445103707084538]\n",
      "\n",
      "EPOCH:\t76\n",
      "train_roc:[0.9039406583996372]\n",
      "valid_roc:[0.8470713525026624]\n",
      "\n",
      "EPOCH:\t77\n",
      "train_roc:[0.9126477540378145]\n",
      "valid_roc:[0.8488868603884578]\n",
      "\n",
      "EPOCH:\t78\n",
      "train_roc:[0.9087202010163389]\n",
      "valid_roc:[0.8484253765403925]\n",
      "\n",
      "EPOCH:\t79\n",
      "train_roc:[0.9084835761328661]\n",
      "valid_roc:[0.847329986307622]\n",
      "\n",
      "EPOCH:\t80\n",
      "train_roc:[0.9139497509558105]\n",
      "valid_roc:[0.8480298189563366]\n",
      "\n",
      "EPOCH:\t81\n",
      "train_roc:[0.9142572232896011]\n",
      "valid_roc:[0.8513362746589582]\n",
      "\n",
      "EPOCH:\t82\n",
      "train_roc:[0.915545638779374]\n",
      "valid_roc:[0.8494852680156194]\n",
      "\n",
      "EPOCH:\t83\n",
      "train_roc:[0.9147780780626892]\n",
      "valid_roc:[0.8475176225974947]\n",
      "\n",
      "EPOCH:\t84\n",
      "train_roc:[0.9171941721391422]\n",
      "valid_roc:[0.8495511942796287]\n",
      "\n",
      "EPOCH:\t85\n",
      "train_roc:[0.9172835015330212]\n",
      "valid_roc:[0.8475835488615041]\n",
      "\n",
      "EPOCH:\t86\n",
      "train_roc:[0.914775557797658]\n",
      "valid_roc:[0.8482732390080633]\n",
      "\n",
      "EPOCH:\t87\n",
      "train_roc:[0.9160585127131968]\n",
      "valid_roc:[0.8538465439423906]\n",
      "\n",
      "EPOCH:\t88\n",
      "train_roc:[0.9135409079618815]\n",
      "valid_roc:[0.8517064759876262]\n",
      "\n",
      "EPOCH:\t89\n",
      "train_roc:[0.9201050782500287]\n",
      "valid_roc:[0.8501445306557128]\n",
      "\n",
      "EPOCH:\t90\n",
      "train_roc:[0.9199827053812978]\n",
      "valid_roc:[0.8456767584563112]\n",
      "\n",
      "EPOCH:\t91\n",
      "train_roc:[0.9190689692928108]\n",
      "valid_roc:[0.8461990973173082]\n",
      "\n",
      "EPOCH:\t92\n",
      "train_roc:[0.9181639141172087]\n",
      "valid_roc:[0.8491607079466503]\n",
      "\n",
      "EPOCH:\t93\n",
      "train_roc:[0.9204951592709489]\n",
      "valid_roc:[0.848673867843197]\n",
      "\n",
      "EPOCH:\t94\n",
      "train_roc:[0.9223133904761425]\n",
      "valid_roc:[0.8471930625285258]\n",
      "\n",
      "EPOCH:\t95\n",
      "train_roc:[0.9175569502888925]\n",
      "valid_roc:[0.8427354328312795]\n",
      "\n",
      "EPOCH:\t96\n",
      "train_roc:[0.9206593965421405]\n",
      "valid_roc:[0.8504082357117501]\n",
      "\n",
      "EPOCH:\t97\n",
      "train_roc:[0.92198883634603]\n",
      "valid_roc:[0.8499923931233836]\n",
      "\n",
      "EPOCH:\t98\n",
      "train_roc:[0.9188816295921679]\n",
      "valid_roc:[0.8561387494294842]\n",
      "\n",
      "EPOCH:\t99\n",
      "train_roc:[0.9170928014790036]\n",
      "valid_roc:[0.8388812820122723]\n",
      "\n",
      "EPOCH:\t100\n",
      "train_roc:[0.9190754099701124]\n",
      "valid_roc:[0.8450834220802271]\n",
      "\n",
      "EPOCH:\t101\n",
      "train_roc:[0.923797546549995]\n",
      "valid_roc:[0.8502865256858866]\n",
      "\n",
      "EPOCH:\t102\n",
      "train_roc:[0.9226824692884703]\n",
      "valid_roc:[0.8481870277397435]\n",
      "\n",
      "EPOCH:\t103\n",
      "train_roc:[0.9217578120515153]\n",
      "valid_roc:[0.8470561387494294]\n",
      "\n",
      "EPOCH:\t104\n",
      "train_roc:[0.9197609220585637]\n",
      "valid_roc:[0.8456361884476902]\n",
      "\n",
      "EPOCH:\t105\n",
      "train_roc:[0.9196693524291014]\n",
      "valid_roc:[0.831122267863482]\n",
      "\n",
      "EPOCH:\t106\n",
      "train_roc:[0.924131901710784]\n",
      "valid_roc:[0.8488513616309143]\n",
      "\n",
      "EPOCH:\t107\n",
      "train_roc:[0.9228896910799139]\n",
      "valid_roc:[0.8456970434606217]\n",
      "\n",
      "EPOCH:\t108\n",
      "train_roc:[0.9258669641699521]\n",
      "valid_roc:[0.845793397231097]\n",
      "\n",
      "EPOCH:\t109\n",
      "train_roc:[0.9256897055294335]\n",
      "valid_roc:[0.8474669100867184]\n",
      "\n",
      "EPOCH:\t110\n",
      "train_roc:[0.9248372958900357]\n",
      "valid_roc:[0.8467163649272275]\n",
      "\n",
      "EPOCH:\t111\n",
      "train_roc:[0.9246437955415392]\n",
      "valid_roc:[0.8468177899487804]\n",
      "\n",
      "EPOCH:\t112\n",
      "train_roc:[0.9193067142940751]\n",
      "valid_roc:[0.8429687103808509]\n",
      "\n",
      "EPOCH:\t113\n",
      "train_roc:[0.9231694404983628]\n",
      "valid_roc:[0.8537349764186826]\n",
      "\n",
      "EPOCH:\t114\n",
      "train_roc:[0.9254264778484105]\n",
      "valid_roc:[0.8509052183173589]\n",
      "\n",
      "EPOCH:\t115\n",
      "train_roc:[0.928294679468493]\n",
      "valid_roc:[0.8425934378011055]\n",
      "\n",
      "EPOCH:\t116\n",
      "train_roc:[0.9244920195807792]\n",
      "valid_roc:[0.8526598711902227]\n",
      "\n",
      "EPOCH:\t117\n",
      "train_roc:[0.9243917690384321]\n",
      "valid_roc:[0.855646838074953]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_param ={}\n",
    "best_param[\"roc_epoch\"] = 0\n",
    "best_param[\"loss_epoch\"] = 0\n",
    "best_param[\"valid_roc\"] = 0\n",
    "best_param[\"valid_loss\"] = 9e8\n",
    "\n",
    "for epoch in range(epochs):    \n",
    "    train_roc, train_prc, train_precision, train_recall, train_loss = eval(model, train_df)\n",
    "    valid_roc, valid_prc, valid_precision, valid_recall, valid_loss = eval(model, valid_df)\n",
    "    train_roc_mean = np.array(train_roc).mean()\n",
    "    valid_roc_mean = np.array(valid_roc).mean()\n",
    "    \n",
    "#     tensorboard.add_scalars('ROC',{'train_roc':train_roc_mean,'valid_roc':valid_roc_mean},epoch)\n",
    "#     tensorboard.add_scalars('Losses',{'train_losses':train_loss,'valid_losses':valid_loss},epoch)\n",
    "\n",
    "    if valid_roc_mean > best_param[\"valid_roc\"]:\n",
    "        best_param[\"roc_epoch\"] = epoch\n",
    "        best_param[\"valid_roc\"] = valid_roc_mean\n",
    "        if valid_roc_mean > 0.81:\n",
    "             torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')             \n",
    "    if valid_loss < best_param[\"valid_loss\"]:\n",
    "        best_param[\"loss_epoch\"] = epoch\n",
    "        best_param[\"valid_loss\"] = valid_loss\n",
    "\n",
    "    print(\"EPOCH:\\t\"+str(epoch)+'\\n'\\\n",
    "        +\"train_roc\"+\":\"+str(train_roc)+'\\n'\\\n",
    "        +\"valid_roc\"+\":\"+str(valid_roc)+'\\n'\\\n",
    "#         +\"train_roc_mean\"+\":\"+str(train_roc_mean)+'\\n'\\\n",
    "#         +\"valid_roc_mean\"+\":\"+str(valid_roc_mean)+'\\n'\\\n",
    "        )\n",
    "    if (epoch - best_param[\"roc_epoch\"] >18) and (epoch - best_param[\"loss_epoch\"] >28):        \n",
    "        break\n",
    "        \n",
    "    train(model, train_df, optimizer, loss_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where((y_val=='0') | (y_val=='1'))[0]\n",
    "#             print(validInds)\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "#             print(validInds)\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "#             print(y_pred_adjust)\n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            #a=list(y_val_list[0].values())\n",
    "            #b=list(y_pred_list[0].values())\n",
    "            #print(len(a[0]))\n",
    "            #print(len(b[0]))\n",
    "            try:\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                y_val_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)  \n",
    "            #c=list(y_val_list[0].values())\n",
    "            #d=list(y_pred_list[0].values())\n",
    "            #print(len(c[0]))\n",
    "            #print(len(d[0]))          \n",
    "    test_roc = [roc_auc_score(y_val_list[i], y_pred_list[i]) for i in range(len(tasks))]\n",
    "    test_prc = [auc(precision_recall_curve(y_val_list[i], y_pred_list[i])[1],precision_recall_curve(y_val_list[i], y_pred_list[i])[0]) for i in range(len(tasks))]\n",
    "#     test_prc = auc(recall, precision)\n",
    "    test_precision = [precision_score(y_val_list[i],\n",
    "                                     (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_recall = [recall_score(y_val_list[i],\n",
    "                               (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_loss = np.array(losses_list).mean()\n",
    "    \n",
    "    return test_roc, test_prc, test_precision, test_recall, test_loss, y_val_list, y_pred_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best epoch:98\n",
      "test_roc:[0.8798053877864059]\n",
      "test_roc_mean: 0.8798053877864059\n"
     ]
    }
   ],
   "source": [
    "# evaluate model\n",
    "best_model = torch.load('saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(best_param[\"roc_epoch\"])+'.pt')     \n",
    "\n",
    "# best_model_dict = best_model.state_dict()\n",
    "# best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "# model.load_state_dict(best_model_wts)\n",
    "# (best_model.align[0].weight == model.align[0].weight).all()\n",
    "\n",
    "test_roc, test_prc, test_precision, test_recall, test_loss, y_val_list, y_pred_list= pred(best_model, test_df)\n",
    "\n",
    "print(\"best epoch:\"+str(best_param[\"roc_epoch\"])\n",
    "      +\"\\n\"+\"test_roc:\"+str(test_roc)\n",
    "      +\"\\n\"+\"test_roc_mean:\",str(np.array(test_roc).mean())\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2607\n",
      "2607\n"
     ]
    }
   ],
   "source": [
    "a=list(y_val_list[0])\n",
    "b=list(y_pred_list[0])\n",
    "print(len(a))\n",
    "print(len(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roc_epoch': 98,\n",
       " 'loss_epoch': 64,\n",
       " 'valid_roc': 0.8561387494294842,\n",
       " 'valid_loss': 0.48905063}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8018406672418752"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score  \n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "y_pred_final=list(map(lambda x: 0 if x<=0.5 else 1,list(y_pred_list[0])))\n",
    "y_true=list(y_val_list[0])\n",
    "balanced_accuracy_score(y_true,y_pred_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
