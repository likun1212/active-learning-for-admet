{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "torch.manual_seed(8) # for reproduce\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import gc\n",
    "import sys\n",
    "sys.setrecursionlimit(50000)\n",
    "import pickle\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "# from tensorboardX import SummaryWriter\n",
    "torch.nn.Module.dump_patches = True\n",
    "import copy\n",
    "import pandas as pd\n",
    "#then import my own modules\n",
    "from AttentiveFP import Fingerprint, Fingerprint_viz, save_smiles_dicts, get_smiles_dicts, get_smiles_array, moltosvg_highlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdkit.Chem import rdMolDescriptors, MolSurf\n",
    "# from rdkit.Chem.Draw import SimilarityMaps\n",
    "from rdkit import Chem\n",
    "# from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import QED\n",
    "%matplotlib inline\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "from IPython.display import SVG, display\n",
    "import seaborn as sns; sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  10839\n",
      "number of successfully processed smiles:  10839\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_name = '500_toxic'\n",
    "tasks = ['500_toxic']\n",
    "raw_filename = \"../data/500_toxic/total_500_1.csv\"\n",
    "feature_filename = raw_filename.replace('.csv','.pickle')\n",
    "filename = raw_filename.replace('.csv','')\n",
    "prefix_filename = raw_filename.split('/')[-1].replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(raw_filename)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(\"not successfully processed smiles: \", smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "smiles_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)]\n",
    "# print(smiles_tasks_df)\n",
    "smiles_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "assert canonical_smiles_list[8]==Chem.MolToSmiles(Chem.MolFromSmiles(smiles_tasks_df['cano_smiles'][8]), isomericSmiles=True)\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.set(font_scale=1.5)\n",
    "ax = sns.distplot(atom_num_dist, bins=28, kde=False)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"atom_num_dist_\"+prefix_filename+\".png\",dpi=200)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# print(len([i for i in atom_num_dist if i<51]),len([i for i in atom_num_dist if i>50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 188\n",
    "random_seed = int(time.time())\n",
    "start_time = str(time.ctime()).replace(':','-').replace(' ','_')\n",
    "start = time.time()\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 800\n",
    "p_dropout = 0.1\n",
    "fingerprint_dim = 150\n",
    "\n",
    "radius = 3\n",
    "T = 2\n",
    "weight_decay = 2.9 # also known as l2_regularization_lambda\n",
    "learning_rate = 3.5\n",
    "per_task_output_units_num = 2 # for classification model with 2 classes\n",
    "output_units_num = len(tasks) * per_task_output_units_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>500_toxic</th>\n",
       "      <th>smiles</th>\n",
       "      <th>cano_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7838</th>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      500_toxic smiles cano_smiles\n",
       "7838          0      C           C"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smilesList = [smiles for smiles in canonical_smiles_list if len(Chem.MolFromSmiles(smiles).GetAtoms())<101]\n",
    "uncovered = [smiles for smiles in canonical_smiles_list if len(Chem.MolFromSmiles(smiles).GetAtoms())>100]\n",
    "\n",
    "smiles_tasks_df = smiles_tasks_df[~smiles_tasks_df[\"cano_smiles\"].isin(uncovered)]\n",
    "\n",
    "if os.path.isfile(feature_filename):\n",
    "    feature_dicts = pickle.load(open(feature_filename, \"rb\" ))\n",
    "else:\n",
    "    feature_dicts = save_smiles_dicts(smilesList,filename)\n",
    "# feature_dicts = get_smiles_dicts(smilesList)\n",
    "\n",
    "remained_df = smiles_tasks_df[smiles_tasks_df[\"cano_smiles\"].isin(feature_dicts['smiles_to_atom_mask'].keys())]\n",
    "uncovered_df = smiles_tasks_df.drop(remained_df.index)\n",
    "uncovered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = []\n",
    "for i,task in enumerate(tasks):    \n",
    "    negative_df = remained_df[remained_df[task] == 0][[\"smiles\",task]]\n",
    "    positive_df = remained_df[remained_df[task] == 1][[\"smiles\",task]]\n",
    "    weights.append([(positive_df.shape[0]+negative_df.shape[0])/negative_df.shape[0],\\\n",
    "                    (positive_df.shape[0]+negative_df.shape[0])/positive_df.shape[0]])\n",
    "    \n",
    "#test_df=remained_df.tail(2579)\n",
    "#training_data = remained_df.drop(test_df.index) # training data\n",
    "training_data = remained_df\n",
    "\n",
    "# training data is further divided into validation set and train set\n",
    "valid_df = training_data.sample(frac=1/5, random_state=random_seed) # validation set\n",
    "train_df = training_data.drop(valid_df.index) # train set\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "valid_df = valid_df.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649206\n",
      "atom_fc.weight torch.Size([150, 39])\n",
      "atom_fc.bias torch.Size([150])\n",
      "neighbor_fc.weight torch.Size([150, 49])\n",
      "neighbor_fc.bias torch.Size([150])\n",
      "GRUCell.0.weight_ih torch.Size([450, 150])\n",
      "GRUCell.0.weight_hh torch.Size([450, 150])\n",
      "GRUCell.0.bias_ih torch.Size([450])\n",
      "GRUCell.0.bias_hh torch.Size([450])\n",
      "GRUCell.1.weight_ih torch.Size([450, 150])\n",
      "GRUCell.1.weight_hh torch.Size([450, 150])\n",
      "GRUCell.1.bias_ih torch.Size([450])\n",
      "GRUCell.1.bias_hh torch.Size([450])\n",
      "GRUCell.2.weight_ih torch.Size([450, 150])\n",
      "GRUCell.2.weight_hh torch.Size([450, 150])\n",
      "GRUCell.2.bias_ih torch.Size([450])\n",
      "GRUCell.2.bias_hh torch.Size([450])\n",
      "align.0.weight torch.Size([1, 300])\n",
      "align.0.bias torch.Size([1])\n",
      "align.1.weight torch.Size([1, 300])\n",
      "align.1.bias torch.Size([1])\n",
      "align.2.weight torch.Size([1, 300])\n",
      "align.2.bias torch.Size([1])\n",
      "attend.0.weight torch.Size([150, 150])\n",
      "attend.0.bias torch.Size([150])\n",
      "attend.1.weight torch.Size([150, 150])\n",
      "attend.1.bias torch.Size([150])\n",
      "attend.2.weight torch.Size([150, 150])\n",
      "attend.2.bias torch.Size([150])\n",
      "mol_GRUCell.weight_ih torch.Size([450, 150])\n",
      "mol_GRUCell.weight_hh torch.Size([450, 150])\n",
      "mol_GRUCell.bias_ih torch.Size([450])\n",
      "mol_GRUCell.bias_hh torch.Size([450])\n",
      "mol_align.weight torch.Size([1, 300])\n",
      "mol_align.bias torch.Size([1])\n",
      "mol_attend.weight torch.Size([150, 150])\n",
      "mol_attend.bias torch.Size([150])\n",
      "output.weight torch.Size([2, 150])\n",
      "output.bias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array([smilesList[0]],feature_dicts)\n",
    "num_atom_features = x_atom.shape[-1]\n",
    "num_bond_features = x_bonds.shape[-1]\n",
    "\n",
    "loss_function = [nn.CrossEntropyLoss(torch.Tensor(weight),reduction='mean') for weight in weights]\n",
    "model = Fingerprint(radius, T, num_atom_features,num_bond_features,\n",
    "            fingerprint_dim, output_units_num, p_dropout)\n",
    "model.cuda()\n",
    "# tensorboard = SummaryWriter(log_dir=\"runs/\"+start_time+\"_\"+prefix_filename+\"_\"+str(fingerprint_dim)+\"_\"+str(p_dropout))\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), learning_rate, weight_decay=weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), 10**-learning_rate, weight_decay=10**-weight_decay)\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(params)\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, optimizer, loss_function):\n",
    "    model.train()\n",
    "    np.random.seed(epoch)\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    #shuffle them\n",
    "    np.random.shuffle(valList)\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, train_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[train_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "#         print(torch.Tensor(x_atom).size(),torch.Tensor(x_bonds).size(),torch.cuda.LongTensor(x_atom_index).size(),torch.cuda.LongTensor(x_bond_index).size(),torch.Tensor(x_mask).size())\n",
    "        \n",
    "        model.zero_grad()\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target wrapped in a variable)\n",
    "        loss = 0.0\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where(y_val != -1)[0]\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "\n",
    "            loss += loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "def eval(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    losses_list = []\n",
    "    valList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = valList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list = batch_df.cano_smiles.values\n",
    "        \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            y_val = batch_df[task].values\n",
    "\n",
    "            validInds = np.where((y_val==0) | (y_val==1))[0]\n",
    "#             validInds = np.where((y_val=='0') | (y_val=='1'))[0]\n",
    "#             print(validInds)\n",
    "            if len(validInds) == 0:\n",
    "                continue\n",
    "            y_val_adjust = np.array([y_val[v] for v in validInds]).astype(float)\n",
    "            validInds = torch.cuda.LongTensor(validInds).squeeze()\n",
    "            y_pred_adjust = torch.index_select(y_pred, 0, validInds)\n",
    "#             print(validInds)\n",
    "            loss = loss_function[i](\n",
    "                y_pred_adjust,\n",
    "                torch.cuda.LongTensor(y_val_adjust))\n",
    "#             print(y_pred_adjust)\n",
    "            y_pred_adjust = F.softmax(y_pred_adjust,dim=-1).data.cpu().numpy()[:,1]\n",
    "            losses_list.append(loss.cpu().detach().numpy())\n",
    "            try:\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "            except:\n",
    "                y_val_list[i] = []\n",
    "                y_pred_list[i] = []\n",
    "                y_val_list[i].extend(y_val_adjust)\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "#             print(y_val,y_pred,validInds,y_val_adjust,y_pred_adjust)            \n",
    "    test_roc = [roc_auc_score(y_val_list[i], y_pred_list[i]) for i in range(len(tasks))]\n",
    "    test_prc = [auc(precision_recall_curve(y_val_list[i], y_pred_list[i])[1],precision_recall_curve(y_val_list[i], y_pred_list[i])[0]) for i in range(len(tasks))]\n",
    "#     test_prc = auc(recall, precision)\n",
    "    test_precision = [precision_score(y_val_list[i],\n",
    "                                     (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_recall = [recall_score(y_val_list[i],\n",
    "                               (np.array(y_pred_list[i]) > 0.5).astype(int)) for i in range(len(tasks))]\n",
    "    test_loss = np.array(losses_list).mean()\n",
    "    \n",
    "    return test_roc, test_prc, test_precision, test_recall, test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:\t0\n",
      "train_roc:[0.5332027356992108]\n",
      "valid_roc:[0.5206467285574606]\n",
      "\n",
      "EPOCH:\t1\n",
      "train_roc:[0.6314981278977212]\n",
      "valid_roc:[0.5973106736419809]\n",
      "\n",
      "EPOCH:\t2\n",
      "train_roc:[0.672982733645134]\n",
      "valid_roc:[0.6260838448899775]\n",
      "\n",
      "EPOCH:\t3\n",
      "train_roc:[0.7191423406928137]\n",
      "valid_roc:[0.6750017639884283]\n",
      "\n",
      "EPOCH:\t4\n",
      "train_roc:[0.7344964716491897]\n",
      "valid_roc:[0.6927152317880795]\n",
      "\n",
      "EPOCH:\t5\n",
      "train_roc:[0.738472559784524]\n",
      "valid_roc:[0.6961524892396705]\n",
      "\n",
      "EPOCH:\t6\n",
      "train_roc:[0.7483814105912198]\n",
      "valid_roc:[0.7107663773725643]\n",
      "\n",
      "EPOCH:\t7\n",
      "train_roc:[0.7474276827207774]\n",
      "valid_roc:[0.711007287792192]\n",
      "\n",
      "EPOCH:\t8\n",
      "train_roc:[0.7500280286765201]\n",
      "valid_roc:[0.7127168445774995]\n",
      "\n",
      "EPOCH:\t9\n",
      "train_roc:[0.7526140387563035]\n",
      "valid_roc:[0.7152962996562742]\n",
      "\n",
      "EPOCH:\t10\n",
      "train_roc:[0.752689231523644]\n",
      "valid_roc:[0.7185873980666687]\n",
      "\n",
      "EPOCH:\t11\n",
      "train_roc:[0.7561838287178401]\n",
      "valid_roc:[0.7204783936617376]\n",
      "\n",
      "EPOCH:\t12\n",
      "train_roc:[0.7611430693442947]\n",
      "valid_roc:[0.7280191921940992]\n",
      "\n",
      "EPOCH:\t13\n",
      "train_roc:[0.7567827044463739]\n",
      "valid_roc:[0.7261906921890592]\n",
      "\n",
      "EPOCH:\t14\n",
      "train_roc:[0.7593367176038848]\n",
      "valid_roc:[0.7253742175451329]\n",
      "\n",
      "EPOCH:\t15\n",
      "train_roc:[0.7626034465202501]\n",
      "valid_roc:[0.730282137349179]\n",
      "\n",
      "EPOCH:\t16\n",
      "train_roc:[0.7616181295314466]\n",
      "valid_roc:[0.7320415898071708]\n",
      "\n",
      "EPOCH:\t17\n",
      "train_roc:[0.7653795559617701]\n",
      "valid_roc:[0.7334462285927404]\n",
      "\n",
      "EPOCH:\t18\n",
      "train_roc:[0.764533331476257]\n",
      "valid_roc:[0.7293880472144103]\n",
      "\n",
      "EPOCH:\t19\n",
      "train_roc:[0.7679348866396098]\n",
      "valid_roc:[0.7355811585875996]\n",
      "\n",
      "EPOCH:\t20\n",
      "train_roc:[0.7684560914078038]\n",
      "valid_roc:[0.7354894311893314]\n",
      "\n",
      "EPOCH:\t21\n",
      "train_roc:[0.7719890535391953]\n",
      "valid_roc:[0.7402108722166783]\n",
      "\n",
      "EPOCH:\t22\n",
      "train_roc:[0.7746618631130258]\n",
      "valid_roc:[0.7437217131855615]\n",
      "\n",
      "EPOCH:\t23\n",
      "train_roc:[0.770464933474948]\n",
      "valid_roc:[0.7444172286229802]\n",
      "\n",
      "EPOCH:\t24\n",
      "train_roc:[0.7758479137347918]\n",
      "valid_roc:[0.7453481105163949]\n",
      "\n",
      "EPOCH:\t25\n",
      "train_roc:[0.7775374453393754]\n",
      "valid_roc:[0.7463520719304081]\n",
      "\n",
      "EPOCH:\t26\n",
      "train_roc:[0.7774075127393236]\n",
      "valid_roc:[0.7486971685465743]\n",
      "\n",
      "EPOCH:\t27\n",
      "train_roc:[0.7778063135950595]\n",
      "valid_roc:[0.7489179190984507]\n",
      "\n",
      "EPOCH:\t28\n",
      "train_roc:[0.7809119913359864]\n",
      "valid_roc:[0.75689820274779]\n",
      "\n",
      "EPOCH:\t29\n",
      "train_roc:[0.7827094027598789]\n",
      "valid_roc:[0.7537089116695396]\n",
      "\n",
      "EPOCH:\t30\n",
      "train_roc:[0.7859480559454265]\n",
      "valid_roc:[0.7592004596449848]\n",
      "\n",
      "EPOCH:\t31\n",
      "train_roc:[0.7876406931336425]\n",
      "valid_roc:[0.761780922717147]\n",
      "\n",
      "EPOCH:\t32\n",
      "train_roc:[0.7885491861394602]\n",
      "valid_roc:[0.7588950376485529]\n",
      "\n",
      "EPOCH:\t33\n",
      "train_roc:[0.7898802267364651]\n",
      "valid_roc:[0.7616700434445149]\n",
      "\n",
      "EPOCH:\t34\n",
      "train_roc:[0.7935538812172608]\n",
      "valid_roc:[0.7658784158375921]\n",
      "\n",
      "EPOCH:\t35\n",
      "train_roc:[0.7931560214474741]\n",
      "valid_roc:[0.7622214158275122]\n",
      "\n",
      "EPOCH:\t36\n",
      "train_roc:[0.7960945309542931]\n",
      "valid_roc:[0.7673823419718365]\n",
      "\n",
      "EPOCH:\t37\n",
      "train_roc:[0.7959363657757657]\n",
      "valid_roc:[0.7651103248762688]\n",
      "\n",
      "EPOCH:\t38\n",
      "train_roc:[0.7970208104845508]\n",
      "valid_roc:[0.7678399709697905]\n",
      "\n",
      "EPOCH:\t39\n",
      "train_roc:[0.7995975038134371]\n",
      "valid_roc:[0.7674468535486407]\n",
      "\n",
      "EPOCH:\t40\n",
      "train_roc:[0.8011750461900669]\n",
      "valid_roc:[0.7742971766105216]\n",
      "\n",
      "EPOCH:\t41\n",
      "train_roc:[0.7955358395957899]\n",
      "valid_roc:[0.764699063574143]\n",
      "\n",
      "EPOCH:\t42\n",
      "train_roc:[0.8004720549860207]\n",
      "valid_roc:[0.7699134133680083]\n",
      "\n",
      "EPOCH:\t43\n",
      "train_roc:[0.8019013449561212]\n",
      "valid_roc:[0.7690304111605027]\n",
      "\n",
      "EPOCH:\t44\n",
      "train_roc:[0.8066042651395476]\n",
      "valid_roc:[0.7801778100335662]\n",
      "\n",
      "EPOCH:\t45\n",
      "train_roc:[0.8055851945346999]\n",
      "valid_roc:[0.775683167518421]\n",
      "\n",
      "EPOCH:\t46\n",
      "train_roc:[0.8071421898681056]\n",
      "valid_roc:[0.7769139274446359]\n",
      "\n",
      "EPOCH:\t47\n",
      "train_roc:[0.8053221610119008]\n",
      "valid_roc:[0.7750572036247442]\n",
      "\n",
      "EPOCH:\t48\n",
      "train_roc:[0.8048343961644348]\n",
      "valid_roc:[0.7763484431542129]\n",
      "\n",
      "EPOCH:\t49\n",
      "train_roc:[0.8110487944908578]\n",
      "valid_roc:[0.7856461741610974]\n",
      "\n",
      "EPOCH:\t50\n",
      "train_roc:[0.8108025122979544]\n",
      "valid_roc:[0.7829467678692027]\n",
      "\n",
      "EPOCH:\t51\n",
      "train_roc:[0.8131914903495088]\n",
      "valid_roc:[0.786194522563932]\n",
      "\n",
      "EPOCH:\t52\n",
      "train_roc:[0.8142554193846012]\n",
      "valid_roc:[0.7858145090568205]\n",
      "\n",
      "EPOCH:\t53\n",
      "train_roc:[0.8114249465447496]\n",
      "valid_roc:[0.7832169100970698]\n",
      "\n",
      "EPOCH:\t54\n",
      "train_roc:[0.8128743757541628]\n",
      "valid_roc:[0.7846482607074098]\n",
      "\n",
      "EPOCH:\t55\n",
      "train_roc:[0.812334349266985]\n",
      "valid_roc:[0.7834487485762094]\n",
      "\n",
      "EPOCH:\t56\n",
      "train_roc:[0.8137225451506374]\n",
      "valid_roc:[0.7879081113227897]\n",
      "\n",
      "EPOCH:\t57\n",
      "train_roc:[0.8173278767915217]\n",
      "valid_roc:[0.7877800961625692]\n",
      "\n",
      "EPOCH:\t58\n",
      "train_roc:[0.8128637101134053]\n",
      "valid_roc:[0.7843755984960736]\n",
      "\n",
      "EPOCH:\t59\n",
      "train_roc:[0.811733842322806]\n",
      "valid_roc:[0.7812634189119718]\n",
      "\n",
      "EPOCH:\t60\n",
      "train_roc:[0.8174993740209962]\n",
      "valid_roc:[0.789128791315129]\n",
      "\n",
      "EPOCH:\t61\n",
      "train_roc:[0.8155568157742066]\n",
      "valid_roc:[0.7851945931234691]\n",
      "\n",
      "EPOCH:\t62\n",
      "train_roc:[0.8190444803019105]\n",
      "valid_roc:[0.7871672361829305]\n",
      "\n",
      "EPOCH:\t63\n",
      "train_roc:[0.8190456096050494]\n",
      "valid_roc:[0.7899200661243663]\n",
      "\n",
      "EPOCH:\t64\n",
      "train_roc:[0.8177109301423744]\n",
      "valid_roc:[0.7871884040440694]\n",
      "\n",
      "EPOCH:\t65\n",
      "train_roc:[0.8225170874544272]\n",
      "valid_roc:[0.7920741479935891]\n",
      "\n",
      "EPOCH:\t66\n",
      "train_roc:[0.8194645497000979]\n",
      "valid_roc:[0.7888636890541998]\n",
      "\n",
      "EPOCH:\t67\n",
      "train_roc:[0.8208198389450603]\n",
      "valid_roc:[0.7901176328283286]\n",
      "\n",
      "EPOCH:\t68\n",
      "train_roc:[0.8216854811706583]\n",
      "valid_roc:[0.7940709828943522]\n",
      "\n",
      "EPOCH:\t69\n",
      "train_roc:[0.8113688578221777]\n",
      "valid_roc:[0.776833287973631]\n",
      "\n",
      "EPOCH:\t70\n",
      "train_roc:[0.8202270802751961]\n",
      "valid_roc:[0.7898757144153133]\n",
      "\n",
      "EPOCH:\t71\n",
      "train_roc:[0.8234876607633599]\n",
      "valid_roc:[0.7958107794812866]\n",
      "\n",
      "EPOCH:\t72\n",
      "train_roc:[0.8251583392794282]\n",
      "valid_roc:[0.7942151259487737]\n",
      "\n",
      "EPOCH:\t73\n",
      "train_roc:[0.8263692973093161]\n",
      "valid_roc:[0.7956495005392764]\n",
      "\n",
      "EPOCH:\t74\n",
      "train_roc:[0.8232708972997296]\n",
      "valid_roc:[0.7914854798552522]\n",
      "\n",
      "EPOCH:\t75\n",
      "train_roc:[0.8188500833143391]\n",
      "valid_roc:[0.783968873164192]\n",
      "\n",
      "EPOCH:\t76\n",
      "train_roc:[0.8237974035187706]\n",
      "valid_roc:[0.7930135978307983]\n",
      "\n",
      "EPOCH:\t77\n",
      "train_roc:[0.826667778402868]\n",
      "valid_roc:[0.796495206991442]\n",
      "\n",
      "EPOCH:\t78\n",
      "train_roc:[0.8258582876389051]\n",
      "valid_roc:[0.7960224580926749]\n",
      "\n",
      "EPOCH:\t79\n",
      "train_roc:[0.8259474712173569]\n",
      "valid_roc:[0.7963792877518723]\n",
      "\n",
      "EPOCH:\t80\n",
      "train_roc:[0.8278992207369168]\n",
      "valid_roc:[0.7959690344431339]\n",
      "\n",
      "EPOCH:\t81\n",
      "train_roc:[0.8298665295441698]\n",
      "valid_roc:[0.7989098551513502]\n",
      "\n",
      "EPOCH:\t82\n",
      "train_roc:[0.8283756611834607]\n",
      "valid_roc:[0.7964750471236908]\n",
      "\n",
      "EPOCH:\t83\n",
      "train_roc:[0.8261696302404293]\n",
      "valid_roc:[0.7947735542854839]\n",
      "\n",
      "EPOCH:\t84\n",
      "train_roc:[0.8309072137563176]\n",
      "valid_roc:[0.7997691695142479]\n",
      "\n",
      "EPOCH:\t85\n",
      "train_roc:[0.8307742383116968]\n",
      "valid_roc:[0.7970284354934631]\n",
      "\n",
      "EPOCH:\t86\n",
      "train_roc:[0.8213733857003745]\n",
      "valid_roc:[0.7918130777062102]\n",
      "\n",
      "EPOCH:\t87\n",
      "train_roc:[0.8309551150311314]\n",
      "valid_roc:[0.7988408076043021]\n",
      "\n",
      "EPOCH:\t88\n",
      "train_roc:[0.8247372346866965]\n",
      "valid_roc:[0.7945417158063443]\n",
      "\n",
      "EPOCH:\t89\n",
      "train_roc:[0.8238395014302311]\n",
      "valid_roc:[0.7904411987057366]\n",
      "\n",
      "EPOCH:\t90\n",
      "train_roc:[0.8305807196710113]\n",
      "valid_roc:[0.7988811273398047]\n",
      "\n",
      "EPOCH:\t91\n",
      "train_roc:[0.8304523555475415]\n",
      "valid_roc:[0.7992329170320642]\n",
      "\n",
      "EPOCH:\t92\n",
      "train_roc:[0.8329187849727143]\n",
      "valid_roc:[0.8006894674770934]\n",
      "\n",
      "EPOCH:\t93\n",
      "train_roc:[0.8302390427323916]\n",
      "valid_roc:[0.7987269043515074]\n",
      "\n",
      "EPOCH:\t94\n",
      "train_roc:[0.8338985809239493]\n",
      "valid_roc:[0.8021122501436391]\n",
      "\n",
      "EPOCH:\t95\n",
      "train_roc:[0.8266106858552835]\n",
      "valid_roc:[0.7923967058776094]\n",
      "\n",
      "EPOCH:\t96\n",
      "train_roc:[0.8320215536287552]\n",
      "valid_roc:[0.804077333252694]\n",
      "\n",
      "EPOCH:\t97\n",
      "train_roc:[0.8344301690071161]\n",
      "valid_roc:[0.8026943663249568]\n",
      "\n",
      "EPOCH:\t98\n",
      "train_roc:[0.827446872090672]\n",
      "valid_roc:[0.7948259699416373]\n",
      "\n",
      "EPOCH:\t99\n",
      "train_roc:[0.8337039329801248]\n",
      "valid_roc:[0.8003759815335612]\n",
      "\n",
      "EPOCH:\t100\n",
      "train_roc:[0.8288773854725064]\n",
      "valid_roc:[0.7981337002429265]\n",
      "\n",
      "EPOCH:\t101\n",
      "train_roc:[0.8362343562498427]\n",
      "valid_roc:[0.8034795931738689]\n",
      "\n",
      "EPOCH:\t102\n",
      "train_roc:[0.8347412606523873]\n",
      "valid_roc:[0.8017508845141976]\n",
      "\n",
      "EPOCH:\t103\n",
      "train_roc:[0.8343534391327253]\n",
      "valid_roc:[0.804349491467336]\n",
      "\n",
      "EPOCH:\t104\n",
      "train_roc:[0.8372424475186167]\n",
      "valid_roc:[0.8035723285655246]\n",
      "\n",
      "EPOCH:\t105\n",
      "train_roc:[0.8378608664653622]\n",
      "valid_roc:[0.8064567016440372]\n",
      "\n",
      "EPOCH:\t106\n",
      "train_roc:[0.8398029227996455]\n",
      "valid_roc:[0.8078522684891186]\n",
      "\n",
      "EPOCH:\t107\n",
      "train_roc:[0.8393759521044972]\n",
      "valid_roc:[0.8078754523370326]\n",
      "\n",
      "EPOCH:\t108\n",
      "train_roc:[0.8368072893757106]\n",
      "valid_roc:[0.8069632183212878]\n",
      "\n",
      "EPOCH:\t109\n",
      "train_roc:[0.8350881763027908]\n",
      "valid_roc:[0.8014081667624262]\n",
      "\n",
      "EPOCH:\t110\n",
      "train_roc:[0.8404273646964655]\n",
      "valid_roc:[0.8070579696997189]\n",
      "\n",
      "EPOCH:\t111\n",
      "train_roc:[0.8401415568936962]\n",
      "valid_roc:[0.8038061830314392]\n",
      "\n",
      "EPOCH:\t112\n",
      "train_roc:[0.8375218559369316]\n",
      "valid_roc:[0.804778896650438]\n",
      "\n",
      "EPOCH:\t113\n",
      "train_roc:[0.8401000236338052]\n",
      "valid_roc:[0.8075155986976725]\n",
      "\n",
      "EPOCH:\t114\n",
      "train_roc:[0.8403553716213523]\n",
      "valid_roc:[0.8069087866783594]\n",
      "\n",
      "EPOCH:\t115\n",
      "train_roc:[0.8418258811560273]\n",
      "valid_roc:[0.8076567177719314]\n",
      "\n",
      "EPOCH:\t116\n",
      "train_roc:[0.8391665291112703]\n",
      "valid_roc:[0.8064521656737931]\n",
      "\n",
      "EPOCH:\t117\n",
      "train_roc:[0.8433830960761547]\n",
      "valid_roc:[0.8061971433467396]\n",
      "\n",
      "EPOCH:\t118\n",
      "train_roc:[0.8264569124111858]\n",
      "valid_roc:[0.7879161752698902]\n",
      "\n",
      "EPOCH:\t119\n",
      "train_roc:[0.8423724011362546]\n",
      "valid_roc:[0.8079419799006118]\n",
      "\n",
      "EPOCH:\t120\n",
      "train_roc:[0.8411305127481699]\n",
      "valid_roc:[0.8041559567369237]\n",
      "\n",
      "EPOCH:\t121\n",
      "train_roc:[0.8386744352684381]\n",
      "valid_roc:[0.8080458032195309]\n",
      "\n",
      "EPOCH:\t122\n",
      "train_roc:[0.8441915830151052]\n",
      "valid_roc:[0.808015563417904]\n",
      "\n",
      "EPOCH:\t123\n",
      "train_roc:[0.8422958281095221]\n",
      "valid_roc:[0.8056951626397331]\n",
      "\n",
      "EPOCH:\t124\n",
      "train_roc:[0.8429807504633436]\n",
      "valid_roc:[0.8092180995292672]\n",
      "\n",
      "EPOCH:\t125\n",
      "train_roc:[0.8386742156817166]\n",
      "valid_roc:[0.802911084903283]\n",
      "\n",
      "EPOCH:\t126\n",
      "train_roc:[0.841980815272796]\n",
      "valid_roc:[0.8052541655326741]\n",
      "\n",
      "EPOCH:\t127\n",
      "train_roc:[0.8442196901154543]\n",
      "valid_roc:[0.8075287026117108]\n",
      "\n",
      "EPOCH:\t128\n",
      "train_roc:[0.8426275609066121]\n",
      "valid_roc:[0.8075599504067252]\n",
      "\n",
      "EPOCH:\t129\n",
      "train_roc:[0.8487698720493269]\n",
      "valid_roc:[0.8108641527311582]\n",
      "\n",
      "EPOCH:\t130\n",
      "train_roc:[0.847783112062068]\n",
      "valid_roc:[0.8122944953481105]\n",
      "\n",
      "EPOCH:\t131\n",
      "train_roc:[0.8472041559861254]\n",
      "valid_roc:[0.8123428790307134]\n",
      "\n",
      "EPOCH:\t132\n",
      "train_roc:[0.8493502083846618]\n",
      "valid_roc:[0.8095588012942636]\n",
      "\n",
      "EPOCH:\t133\n",
      "train_roc:[0.843479369168757]\n",
      "valid_roc:[0.8074097593919783]\n",
      "\n",
      "EPOCH:\t134\n",
      "train_roc:[0.8489280372278543]\n",
      "valid_roc:[0.8095487213603878]\n",
      "\n",
      "EPOCH:\t135\n",
      "train_roc:[0.8392470860685213]\n",
      "valid_roc:[0.8004485570574658]\n",
      "\n",
      "EPOCH:\t136\n",
      "train_roc:[0.8468196596368173]\n",
      "valid_roc:[0.8093572026167507]\n",
      "\n",
      "EPOCH:\t137\n",
      "train_roc:[0.8473751199335617]\n",
      "valid_roc:[0.8104407955083814]\n",
      "\n",
      "EPOCH:\t138\n",
      "train_roc:[0.8463750278953561]\n",
      "valid_roc:[0.8084308566935801]\n",
      "\n",
      "EPOCH:\t139\n",
      "train_roc:[0.8518022078252802]\n",
      "valid_roc:[0.8132299132117692]\n",
      "\n",
      "EPOCH:\t140\n",
      "train_roc:[0.8461087946803297]\n",
      "valid_roc:[0.8078361405949176]\n",
      "\n",
      "EPOCH:\t141\n",
      "train_roc:[0.8491049927558341]\n",
      "valid_roc:[0.8097946717469533]\n",
      "\n",
      "EPOCH:\t142\n",
      "train_roc:[0.852023300284277]\n",
      "valid_roc:[0.8108974165129476]\n",
      "\n",
      "EPOCH:\t143\n",
      "train_roc:[0.8523947782779544]\n",
      "valid_roc:[0.8097110082957855]\n",
      "\n",
      "EPOCH:\t144\n",
      "train_roc:[0.849428443996571]\n",
      "valid_roc:[0.8065015573497838]\n",
      "\n",
      "EPOCH:\t145\n",
      "train_roc:[0.8484587490345242]\n",
      "valid_roc:[0.8100224782525427]\n",
      "\n",
      "EPOCH:\t146\n",
      "train_roc:[0.8494928142754958]\n",
      "valid_roc:[0.807484350902658]\n",
      "\n",
      "EPOCH:\t147\n",
      "train_roc:[0.8496641232877804]\n",
      "valid_roc:[0.8084026328787284]\n",
      "\n",
      "EPOCH:\t148\n",
      "train_roc:[0.8502935529401312]\n",
      "valid_roc:[0.8100486860806193]\n",
      "\n",
      "EPOCH:\t149\n",
      "train_roc:[0.8509270606315954]\n",
      "valid_roc:[0.8120062092392674]\n",
      "\n",
      "EPOCH:\t150\n",
      "train_roc:[0.8557916907506246]\n",
      "valid_roc:[0.8138316852641446]\n",
      "\n",
      "EPOCH:\t151\n",
      "train_roc:[0.8502859615134744]\n",
      "valid_roc:[0.8105577227413389]\n",
      "\n",
      "EPOCH:\t152\n",
      "train_roc:[0.848255380360904]\n",
      "valid_roc:[0.8057143145140968]\n",
      "\n",
      "EPOCH:\t153\n",
      "train_roc:[0.8525413680993068]\n",
      "valid_roc:[0.809654560666082]\n",
      "\n",
      "EPOCH:\t154\n",
      "train_roc:[0.8547302712780631]\n",
      "valid_roc:[0.8157226808592135]\n",
      "\n",
      "EPOCH:\t155\n",
      "train_roc:[0.8535735511683801]\n",
      "valid_roc:[0.8142288346588447]\n",
      "\n",
      "EPOCH:\t156\n",
      "train_roc:[0.8516871757527574]\n",
      "valid_roc:[0.8116201477718307]\n",
      "\n",
      "EPOCH:\t157\n",
      "train_roc:[0.8512465593113459]\n",
      "valid_roc:[0.8044452508391544]\n",
      "\n",
      "EPOCH:\t158\n",
      "train_roc:[0.8549028664411448]\n",
      "valid_roc:[0.812477950144647]\n",
      "\n",
      "EPOCH:\t159\n",
      "train_roc:[0.8575756446454437]\n",
      "valid_roc:[0.8144334573165202]\n",
      "\n",
      "EPOCH:\t160\n",
      "train_roc:[0.8566132901538004]\n",
      "valid_roc:[0.8167316822401645]\n",
      "\n",
      "EPOCH:\t161\n",
      "train_roc:[0.8579815036457984]\n",
      "valid_roc:[0.8161752698902296]\n",
      "\n",
      "EPOCH:\t162\n",
      "train_roc:[0.8575533722779796]\n",
      "valid_roc:[0.8150029735804932]\n",
      "\n",
      "EPOCH:\t163\n",
      "train_roc:[0.8567691339869865]\n",
      "valid_roc:[0.8127198685576621]\n",
      "\n",
      "EPOCH:\t164\n",
      "train_roc:[0.8563642788116443]\n",
      "valid_roc:[0.8136935901700484]\n",
      "\n",
      "EPOCH:\t165\n",
      "train_roc:[0.8547998802687716]\n",
      "valid_roc:[0.8119830253913535]\n",
      "\n",
      "EPOCH:\t166\n",
      "train_roc:[0.8520126660130511]\n",
      "valid_roc:[0.8092160835424919]\n",
      "\n",
      "EPOCH:\t167\n",
      "train_roc:[0.8566623207317533]\n",
      "valid_roc:[0.8139657483846905]\n",
      "\n",
      "EPOCH:\t168\n",
      "train_roc:[0.857355587380991]\n",
      "valid_roc:[0.8123680788654026]\n",
      "\n",
      "EPOCH:\t169\n",
      "train_roc:[0.8574930800381679]\n",
      "valid_roc:[0.8167185783261262]\n",
      "\n",
      "EPOCH:\t170\n",
      "train_roc:[0.8602306363253027]\n",
      "valid_roc:[0.8149253580896509]\n",
      "\n",
      "EPOCH:\t171\n",
      "train_roc:[0.8608837186045102]\n",
      "valid_roc:[0.8159323434838267]\n",
      "\n",
      "EPOCH:\t172\n",
      "train_roc:[0.859155916171326]\n",
      "valid_roc:[0.8156904250708115]\n",
      "\n",
      "EPOCH:\t173\n",
      "train_roc:[0.8595597988911874]\n",
      "valid_roc:[0.8139213966756378]\n",
      "\n",
      "EPOCH:\t174\n",
      "train_roc:[0.8492515198381232]\n",
      "valid_roc:[0.8032336427873034]\n",
      "\n",
      "EPOCH:\t175\n",
      "train_roc:[0.8517822881726891]\n",
      "valid_roc:[0.8106998498089851]\n",
      "\n",
      "EPOCH:\t176\n",
      "train_roc:[0.8576487356541642]\n",
      "valid_roc:[0.814481840999123]\n",
      "\n",
      "EPOCH:\t177\n",
      "train_roc:[0.8610327238797988]\n",
      "valid_roc:[0.8138982128277237]\n",
      "\n",
      "EPOCH:\t178\n",
      "train_roc:[0.8601878169146147]\n",
      "valid_roc:[0.8118912979930852]\n",
      "\n",
      "EPOCH:\t179\n",
      "train_roc:[0.8593094072896393]\n",
      "valid_roc:[0.8141804509762415]\n",
      "\n",
      "EPOCH:\t180\n",
      "train_roc:[0.8603557693870135]\n",
      "valid_roc:[0.8126462850403702]\n",
      "\n",
      "EPOCH:\t181\n",
      "train_roc:[0.8578107592850832]\n",
      "valid_roc:[0.8147711351013538]\n",
      "\n",
      "EPOCH:\t182\n",
      "train_roc:[0.8579676696823453]\n",
      "valid_roc:[0.8125515336619391]\n",
      "\n",
      "EPOCH:\t183\n",
      "train_roc:[0.8571778476147204]\n",
      "valid_roc:[0.8134264719223442]\n",
      "\n",
      "EPOCH:\t184\n",
      "train_roc:[0.8569992295015637]\n",
      "valid_roc:[0.8118025945749796]\n",
      "\n",
      "EPOCH:\t185\n",
      "train_roc:[0.8622302557501449]\n",
      "valid_roc:[0.814202626830768]\n",
      "\n",
      "EPOCH:\t186\n",
      "train_roc:[0.8589240012239137]\n",
      "valid_roc:[0.8113802453455905]\n",
      "\n",
      "EPOCH:\t187\n",
      "train_roc:[0.8609464890373213]\n",
      "valid_roc:[0.8152207001522069]\n",
      "\n",
      "EPOCH:\t188\n",
      "train_roc:[0.8578748158686916]\n",
      "valid_roc:[0.8075115667241222]\n",
      "\n",
      "EPOCH:\t189\n",
      "train_roc:[0.85978751032136]\n",
      "valid_roc:[0.8133730482728034]\n",
      "\n",
      "EPOCH:\t190\n",
      "train_roc:[0.860176900317604]\n",
      "valid_roc:[0.8157176408922757]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_param ={}\n",
    "best_param[\"roc_epoch\"] = 0\n",
    "best_param[\"loss_epoch\"] = 0\n",
    "best_param[\"valid_roc\"] = 0\n",
    "best_param[\"valid_loss\"] = 9e8\n",
    "train_roc_list=[]\n",
    "valid_roc_list=[]\n",
    "for epoch in range(epochs):    \n",
    "    train_roc, train_prc, train_precision, train_recall, train_loss = eval(model, train_df)\n",
    "    valid_roc, valid_prc, valid_precision, valid_recall, valid_loss = eval(model, valid_df)\n",
    "    train_roc_mean = np.array(train_roc).mean()\n",
    "    valid_roc_mean = np.array(valid_roc).mean()\n",
    "    \n",
    "#     tensorboard.add_scalars('ROC',{'train_roc':train_roc_mean,'valid_roc':valid_roc_mean},epoch)\n",
    "#     tensorboard.add_scalars('Losses',{'train_losses':train_loss,'valid_losses':valid_loss},epoch)\n",
    "\n",
    "    if valid_roc_mean > best_param[\"valid_roc\"]:\n",
    "        best_param[\"roc_epoch\"] = epoch\n",
    "        best_param[\"valid_roc\"] = valid_roc_mean\n",
    "        if valid_roc_mean > 0.81:\n",
    "             torch.save(model, 'saved_models/model_'+prefix_filename+'_'+start_time+'_'+str(epoch)+'.pt')             \n",
    "    if valid_loss < best_param[\"valid_loss\"]:\n",
    "        best_param[\"loss_epoch\"] = epoch\n",
    "        best_param[\"valid_loss\"] = valid_loss\n",
    "        \n",
    "    train_roc_list.append(train_roc)\n",
    "    valid_roc_list.append(valid_roc)\n",
    "    \n",
    "    print(\"EPOCH:\\t\"+str(epoch)+'\\n'\\\n",
    "        +\"train_roc\"+\":\"+str(train_roc)+'\\n'\\\n",
    "        +\"valid_roc\"+\":\"+str(valid_roc)+'\\n'\\\n",
    "#         +\"train_roc_mean\"+\":\"+str(train_roc_mean)+'\\n'\\\n",
    "#         +\"valid_roc_mean\"+\":\"+str(valid_roc_mean)+'\\n'\\\n",
    "        )\n",
    "    if (epoch - best_param[\"roc_epoch\"] >18) and (epoch - best_param[\"loss_epoch\"] >28):        \n",
    "        break\n",
    "        \n",
    "    train(model, train_df, optimizer, loss_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "best_model = torch.load('/code/saved_models/model_total_nontoxic_Wed_Mar__9_08-49-46_2022_160.pt')     \n",
    "# best_model_dict = best_model.state_dict()\n",
    "# best_model_wts = copy.deepcopy(best_model_dict)\n",
    "\n",
    "# model.load_state_dict(best_model_wts)\n",
    "# (best_model.align[0].weight == model.align[0].weight).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(model, dataset):\n",
    "    model.eval()\n",
    "    y_val_list = {}\n",
    "    y_pred_list = {}\n",
    "    predList = np.arange(0,dataset.shape[0])\n",
    "    batch_list = []\n",
    "    smiles_list=[]\n",
    "    for i in range(0, dataset.shape[0], batch_size):\n",
    "        batch = predList[i:i+batch_size]\n",
    "        batch_list.append(batch)   \n",
    "    for counter, test_batch in enumerate(batch_list):\n",
    "        batch_df = dataset.loc[test_batch,:]\n",
    "        smiles_list.extend(batch_df.cano_smiles.values.tolist())                                                                                                                            \n",
    "        x_atom, x_bonds, x_atom_index, x_bond_index, x_mask, smiles_to_rdkit_list = get_smiles_array(smiles_list,feature_dicts)\n",
    "        atoms_prediction, mol_prediction = model(torch.Tensor(x_atom),torch.Tensor(x_bonds),torch.cuda.LongTensor(x_atom_index),torch.cuda.LongTensor(x_bond_index),torch.Tensor(x_mask))\n",
    "        atom_pred = atoms_prediction.data[:,:,1].unsqueeze(2).cpu().numpy()\n",
    "        for i,task in enumerate(tasks):\n",
    "            y_pred = mol_prediction[:, i * per_task_output_units_num:(i + 1) *\n",
    "                                    per_task_output_units_num]\n",
    "            if len(y_pred) == 0:\n",
    "                continue\n",
    "            y_pred_adjust = F.softmax(y_pred,dim=-1).data.cpu().numpy()[:,1]\n",
    "            y_val = batch_df[task].values\n",
    "            try:\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "                y_val_list[i].extend(y_val)\n",
    "            except:\n",
    "                y_pred_list[i] = []\n",
    "                y_pred_list[i].extend(y_pred_adjust)\n",
    "                y_val_list[i] = []\n",
    "                y_val_list[i].extend(y_val)\n",
    "    if (len(smiles_list)==len(list(y_val_list[0]))==len(list(y_pred_list[0]))):\n",
    "        print(\"predict successfully:\",len(smiles_list),len(list(y_val_list[0])),len(list(y_pred_list[0])))\n",
    "    return y_val_list, y_pred_list, smiles_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of all smiles:  2581\n",
      "number of successfully processed smiles:  2581\n",
      "feature dicts file saved as ../data/500_toxic/test_500_2581.pickle\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 340.00 MiB (GPU 0; 15.75 GiB total capacity; 9.71 GiB already allocated; 250.56 MiB free; 975.35 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1f20f0fd3907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/code/saved_models/model_total_nontoxic_Wed_Mar__9_08-49-46_2022_160.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0my_val_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msmiles_list\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_tasks_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mdf_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'smiles'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'true'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-797afe214f7a>\u001b[0m in \u001b[0;36mpred\u001b[0;34m(model, dataset)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msmiles_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcano_smiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx_atom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_bonds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_atom_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_bond_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmiles_to_rdkit_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_smiles_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0matoms_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_atom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_bonds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_atom_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_bond_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0matom_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matoms_prediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/code/AttentiveFP/AttentiveLayers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, atom_list, bond_list, atom_degree_list, bond_degree_list, atom_mask)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;31m# neighbor_feature is a list of 3D tensor, so we need to stack them into a 4D tensor first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mneighbor_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbor_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0matom_feature_expand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivated_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmol_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_neighbor_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfingerprint_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 340.00 MiB (GPU 0; 15.75 GiB total capacity; 9.71 GiB already allocated; 250.56 MiB free; 975.35 MiB cached)"
     ]
    }
   ],
   "source": [
    "task_name = '500_toxic'\n",
    "tasks = ['500_toxic']\n",
    "test_df = \"../data/500_toxic/test_500_2581.csv\"\n",
    "\n",
    "per_task_output_units_num = 2\n",
    "batch_size = 100\n",
    "\n",
    "filename=test_df.replace('.csv','')\n",
    "smiles_tasks_df = pd.read_csv(test_df)\n",
    "smilesList = smiles_tasks_df.smiles.values\n",
    "print(\"number of all smiles: \",len(smilesList))\n",
    "atom_num_dist = []\n",
    "remained_smiles = []\n",
    "canonical_smiles_list = []\n",
    "for smiles in smilesList:\n",
    "    try:        \n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        atom_num_dist.append(len(mol.GetAtoms()))\n",
    "        remained_smiles.append(smiles)\n",
    "        canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "    except:\n",
    "        print(\"not successfully processed smiles: \", smiles)\n",
    "        pass\n",
    "print(\"number of successfully processed smiles: \", len(remained_smiles))\n",
    "test_tasks_df = smiles_tasks_df[smiles_tasks_df[\"smiles\"].isin(remained_smiles)]\n",
    "# print(smiles_tasks_df)\n",
    "test_tasks_df['cano_smiles'] =canonical_smiles_list\n",
    "\n",
    "feature_dicts = save_smiles_dicts(canonical_smiles_list,filename)\n",
    "\n",
    "best_model = torch.load('/code/saved_models/model_total_nontoxic_Wed_Mar__9_08-49-46_2022_160.pt')  \n",
    "y_val_list, y_pred_list,smiles_list= pred(best_model, test_tasks_df)\n",
    "\n",
    "df_result=pd.DataFrame(columns=['smiles','true','predict'])\n",
    "df_result['smiles']=smiles_list\n",
    "df_result['true']=y_val_list[0]\n",
    "df_result['predict']=y_pred_list[0]\n",
    "df_result.to_csv('../data/500_toxic/predict_output.csv')\n",
    "\n",
    "from sklearn.metrics import r2_score  \n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "y_pred_final=list(map(lambda x: 0 if x<=0.5 else 1,list(y_pred_list[0])))\n",
    "y_true=list(y_val_list[0])\n",
    "print(\"BA:\", balanced_accuracy_score(y_true,y_pred_final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
